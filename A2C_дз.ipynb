{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adrenalinovaya/RL/blob/main/A2C_%D0%B4%D0%B7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6122c6bd",
      "metadata": {
        "id": "6122c6bd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d188ece-570b-4233-b2e3-6143c51b4adc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cpu\n",
            "Collecting torch==1.13.1\n",
            "  Downloading https://download.pytorch.org/whl/cpu/torch-1.13.1%2Bcpu-cp310-cp310-linux_x86_64.whl (199.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.1/199.1 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==1.13.1) (4.12.2)\n",
            "Installing collected packages: torch\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.4.0+cu121\n",
            "    Uninstalling torch-2.4.0+cu121:\n",
            "      Successfully uninstalled torch-2.4.0+cu121\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.4.0+cu121 requires torch==2.4.0, but you have torch 1.13.1+cpu which is incompatible.\n",
            "torchvision 0.19.0+cu121 requires torch==2.4.0, but you have torch 1.13.1+cpu which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed torch-1.13.1+cpu\n"
          ]
        }
      ],
      "source": [
        "!pip install torch==1.13.1 --extra-index-url https://download.pytorch.org/whl/cpu"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title установка библиотек\n",
        "!pip install rarfile --quiet\n",
        "!pip install stable-baselines3[extra] --quiet\n",
        "!pip install ale-py --quiet\n",
        "!pip install gym[box2d] --quiet\n",
        "!pip install pyvirtualdisplay --quiet\n",
        "!pip install pyglet --quiet\n",
        "!pip install pygame --quiet\n",
        "!pip install minigrid --quiet\n",
        "!pip install -q swig --quiet\n",
        "!pip install -q gymnasium[box2d] --quiet\n",
        "!pip install 'minigrid<=2.1.1' --quiet\n",
        "!pip3 install box2d-py --quiet\n",
        "\n",
        "\n",
        "# @title установка драйверов\n",
        "!apt-get update > /dev/null 2>&1\n",
        "!apt-get install -y xvfb python-opengl ffmpeg > /dev/null 2>&1\n",
        "!apt-get install -y swig build-essential python-dev python3-dev > /dev/null 2>&1\n",
        "!apt-get install x11-utils > /dev/null 2>&1\n",
        "!apt-get install xvfb > /dev/null 2>&1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4SP5hVytjf7c",
        "outputId": "1ace20e6-9644-486a-dfdd-761083a71d1d"
      },
      "id": "4SP5hVytjf7c",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/434.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━\u001b[0m \u001b[32m286.7/434.7 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m434.7/434.7 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m953.9/953.9 kB\u001b[0m \u001b[31m23.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m182.3/182.3 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m58.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for AutoROM.accept-rom-license (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m374.4/374.4 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m52.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m53.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py bdist_wheel\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Building wheel for box2d-py (setup.py) ... \u001b[?25lerror\n",
            "\u001b[31m  ERROR: Failed building wheel for box2d-py\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: ERROR: Failed to build installable wheels for some pyproject.toml based projects (box2d-py)\u001b[0m\u001b[31m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m936.6/936.6 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.8/103.8 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for box2d-py (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m100.3/100.3 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install TensorFlow==v2.16.1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "qOkudK1CTVRw",
        "outputId": "2e70091e-9555-4854-daa9-be9995fef421"
      },
      "id": "qOkudK1CTVRw",
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting TensorFlow==v2.16.1\n",
            "  Using cached tensorflow-2.16.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from TensorFlow==v2.16.1) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from TensorFlow==v2.16.1) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from TensorFlow==v2.16.1) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from TensorFlow==v2.16.1) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from TensorFlow==v2.16.1) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from TensorFlow==v2.16.1) (3.11.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from TensorFlow==v2.16.1) (18.1.1)\n",
            "Collecting ml-dtypes~=0.3.1 (from TensorFlow==v2.16.1)\n",
            "  Downloading ml_dtypes-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from TensorFlow==v2.16.1) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from TensorFlow==v2.16.1) (24.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from TensorFlow==v2.16.1) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from TensorFlow==v2.16.1) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from TensorFlow==v2.16.1) (71.0.4)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from TensorFlow==v2.16.1) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from TensorFlow==v2.16.1) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from TensorFlow==v2.16.1) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from TensorFlow==v2.16.1) (1.16.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from TensorFlow==v2.16.1) (1.64.1)\n",
            "Collecting tensorboard<2.17,>=2.16 (from TensorFlow==v2.16.1)\n",
            "  Downloading tensorboard-2.16.2-py3-none-any.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: keras>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from TensorFlow==v2.16.1) (3.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from TensorFlow==v2.16.1) (0.37.1)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from TensorFlow==v2.16.1) (1.26.4)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->TensorFlow==v2.16.1) (0.44.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.0.0->TensorFlow==v2.16.1) (13.8.1)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.0.0->TensorFlow==v2.16.1) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.0.0->TensorFlow==v2.16.1) (0.12.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->TensorFlow==v2.16.1) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->TensorFlow==v2.16.1) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->TensorFlow==v2.16.1) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->TensorFlow==v2.16.1) (2024.8.30)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.17,>=2.16->TensorFlow==v2.16.1) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.17,>=2.16->TensorFlow==v2.16.1) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.17,>=2.16->TensorFlow==v2.16.1) (3.0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->TensorFlow==v2.16.1) (2.1.5)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.0.0->TensorFlow==v2.16.1) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.0.0->TensorFlow==v2.16.1) (2.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->TensorFlow==v2.16.1) (0.1.2)\n",
            "Downloading tensorflow-2.16.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (589.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m589.8/589.8 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ml_dtypes-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m77.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard-2.16.2-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m95.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: ml-dtypes, tensorboard, TensorFlow\n",
            "  Attempting uninstall: ml-dtypes\n",
            "    Found existing installation: ml-dtypes 0.4.0\n",
            "    Uninstalling ml-dtypes-0.4.0:\n",
            "      Successfully uninstalled ml-dtypes-0.4.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.17.0\n",
            "    Uninstalling tensorboard-2.17.0:\n",
            "      Successfully uninstalled tensorboard-2.17.0\n",
            "  Attempting uninstall: TensorFlow\n",
            "    Found existing installation: tensorflow 2.17.0\n",
            "    Uninstalling tensorflow-2.17.0:\n",
            "      Successfully uninstalled tensorflow-2.17.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tf-keras 2.17.0 requires tensorflow<2.18,>=2.17, but you have tensorflow 2.16.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed TensorFlow-2.16.1 ml-dtypes-0.3.2 tensorboard-2.16.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "ml_dtypes",
                  "tensorboard",
                  "tensorflow"
                ]
              },
              "id": "4ab356679b0049cd9c292cfde94ab53b"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import gymnasium as gym\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "2N8P-r-vv61u"
      },
      "id": "2N8P-r-vv61u",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim"
      ],
      "metadata": {
        "id": "uKkyoM66ytdn"
      },
      "id": "uKkyoM66ytdn",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class OrnsteinUhlenbeckActionNoise:\n",
        "    def __init__(self, mu, sigma, theta=.15, dt=1e-2, x0=None):\n",
        "        self.theta = theta\n",
        "        self.mu = mu\n",
        "        self.sigma = sigma\n",
        "        self.dt = dt\n",
        "        self.x0 = x0\n",
        "        self.reset()\n",
        "\n",
        "    def __call__(self):\n",
        "        x = self.x_prev + self.theta * (self.mu - self.x_prev) * self.dt + self.sigma * np.sqrt(self.dt) * np.random.normal(size=self.mu.shape)\n",
        "        self.x_prev = x\n",
        "        return x\n",
        "\n",
        "    def reset(self):\n",
        "        self.x_prev = self.x0 if self.x0 is not None else np.zeros_like(self.mu)\n",
        "\n",
        "ou_action_noise = OrnsteinUhlenbeckActionNoise(mu=np.zeros(1), sigma=np.ones(1) * 0.05)"
      ],
      "metadata": {
        "id": "qTCN82ZS0bXX"
      },
      "id": "qTCN82ZS0bXX",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import copy\n",
        "import random\n",
        "from collections import deque, namedtuple\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "\"\"\"\n",
        "Hyperparameters:\n",
        "\n",
        "actor_layer_sizes\n",
        "critic_layer_sizes\n",
        "max_buffer_size\n",
        "tau\n",
        "max_time_steps\n",
        "max_episodes\n",
        "actor_lr\n",
        "critic_lr\n",
        "GAMMA\n",
        "update_after\n",
        "batch_size\n",
        "\"\"\"\n",
        "\n",
        "device = torch.device(\"cpu\")\n",
        "dtype = torch.double\n",
        "\n",
        "Transition = namedtuple(\n",
        "    \"Transition\", (\"state\", \"action\", \"reward\", \"next_state\", \"done\")\n",
        ")\n",
        "\n",
        "\n",
        "class agent:\n",
        "    def __init__(\n",
        "        self,\n",
        "        env,\n",
        "        actor_layer_sizes=[32, 32],\n",
        "        critic_layer_sizes=[64, 64],\n",
        "        max_buffer_size=1000000,\n",
        "    ):\n",
        "        self.env = env\n",
        "        (\n",
        "            self.actor,\n",
        "            self.critic,\n",
        "            self.target_actor,\n",
        "            self.target_critic,\n",
        "        ) = self.make_models(actor_layer_sizes, critic_layer_sizes)\n",
        "        self.replay_buffer = deque(maxlen=max_buffer_size)\n",
        "        self.max_buffer_size = max_buffer_size\n",
        "\n",
        "    def make_models(self, actor_layer_sizes, critic_layer_sizes):\n",
        "        actor = (\n",
        "            nn.Sequential(\n",
        "                nn.Linear(\n",
        "                    self.env.observation_space.shape[0],\n",
        "                    actor_layer_sizes[0],\n",
        "                ),\n",
        "                nn.ReLU(),\n",
        "                nn.Linear(actor_layer_sizes[0], actor_layer_sizes[1]),\n",
        "                nn.ReLU(),\n",
        "                nn.Linear(\n",
        "                    actor_layer_sizes[1], self.env.action_space.shape[0]\n",
        "                ), nn.Tanh()\n",
        "            )\n",
        "            .to(device)\n",
        "            .to(dtype)\n",
        "        )\n",
        "\n",
        "        critic = (\n",
        "            nn.Sequential(\n",
        "                nn.Linear(\n",
        "                    self.env.observation_space.shape[0]\n",
        "                    + self.env.action_space.shape[0],\n",
        "                    critic_layer_sizes[0],\n",
        "                ),\n",
        "                nn.ReLU(),\n",
        "                nn.Linear(critic_layer_sizes[0], critic_layer_sizes[1]),\n",
        "                nn.Linear(critic_layer_sizes[1], 1),\n",
        "            )\n",
        "            .to(device)\n",
        "            .to(dtype)\n",
        "        )\n",
        "\n",
        "        target_actor = copy.deepcopy(actor)    # Create a target actor network\n",
        "\n",
        "        target_critic = copy.deepcopy(critic)   # Create a target critic network\n",
        "\n",
        "        return actor, critic, target_actor, target_critic\n",
        "\n",
        "    def select_action(self, state, noise_factor):         # Selects an action in exploratory manner\n",
        "      with torch.no_grad():\n",
        "        noisy_action = self.actor(state) + noise_factor * torch.randn(size = self.env.action_space.shape, device=device, dtype=dtype)\n",
        "        action = torch.clamp(noisy_action, self.env.action_space.low[0], self.env.action_space.high[0])\n",
        "\n",
        "        return action\n",
        "\n",
        "    def store_transition(self, state, action, reward, next_state, done):             # Stores the transition to the replay buffer with a default maximum capacity of 2500\n",
        "        if len(self.replay_buffer) < self.max_buffer_size:\n",
        "            self.replay_buffer.append(\n",
        "                Transition(state, action, reward, next_state, done)\n",
        "            )\n",
        "        else:\n",
        "            self.replay_buffer.popleft()\n",
        "            self.replay_buffer.append(\n",
        "                Transition(state, action, reward, next_state, done)\n",
        "            )\n",
        "\n",
        "    def sample_batch(self, batch_size=128):                                            # Samples a random batch of transitions for training\n",
        "      return Transition(\n",
        "            *[torch.cat(i) for i in [*zip(*random.sample(self.replay_buffer, min(len(self.replay_buffer), batch_size)))]]\n",
        "        )\n",
        "\n",
        "\n",
        "    def train(\n",
        "        self,\n",
        "        GAMMA=0.99,\n",
        "        actor_lr=0.001,\n",
        "        critic_lr=0.001,\n",
        "        tau=0.001,\n",
        "        max_time_steps=5000,\n",
        "        max_episodes=200,\n",
        "        update_after=1,\n",
        "        batch_size=64,\n",
        "        noise_factor=np.random.normal() #0.2,\n",
        "    ):\n",
        "\n",
        "        self.train_rewards_list = []\n",
        "        actor_optimizer = optim.Adam(self.actor.parameters(), lr=actor_lr)\n",
        "        critic_optimizer = optim.Adam(\n",
        "            self.critic.parameters(), lr=critic_lr\n",
        "        )\n",
        "        print(\"Starting Training:\\n\")\n",
        "        for e in range(max_episodes):\n",
        "            state = self.env.reset()\n",
        "            state = torch.tensor(state, device=device, dtype=dtype).unsqueeze(0)\n",
        "            episode_reward = 0\n",
        "            for t in range(max_time_steps):\n",
        "                #self.env.render()\n",
        "                action = self.select_action(state, noise_factor)\n",
        "                next_state, reward, done, _ = self.env.step(action[0])         # Sample a transition\n",
        "                episode_reward += reward\n",
        "\n",
        "                next_state = torch.tensor(next_state, device=device, dtype=dtype).unsqueeze(0)\n",
        "                reward = torch.tensor(\n",
        "                    [reward], device=device, dtype=dtype\n",
        "                ).unsqueeze(0)\n",
        "                done = torch.tensor(\n",
        "                    [done], device=device, dtype=dtype\n",
        "                ).unsqueeze(0)\n",
        "\n",
        "                self.store_transition(\n",
        "                    state, action, reward, next_state, done\n",
        "                )                # Store the transition in the replay buffer\n",
        "\n",
        "                state = next_state\n",
        "\n",
        "                sample_batch = self.sample_batch(64)\n",
        "\n",
        "                with torch.no_grad():                 # Determine the target for the critic to train on\n",
        "                  target = sample_batch.reward + (1 - sample_batch.done) * GAMMA * self.target_critic(torch.cat((sample_batch.next_state, self.target_actor(sample_batch.next_state)), dim=1))\n",
        "\n",
        "                # Train the critic on the sampled batch\n",
        "                critic_loss = nn.MSELoss()(\n",
        "                    target,\n",
        "                    self.critic(\n",
        "                        torch.cat(\n",
        "                            (sample_batch.state, sample_batch.action), dim=1\n",
        "                        )\n",
        "                    ),\n",
        "                )\n",
        "\n",
        "                critic_optimizer.zero_grad()\n",
        "                critic_loss.backward()\n",
        "                critic_optimizer.step()\n",
        "\n",
        "                actor_loss = -1 * torch.mean(\n",
        "                  self.critic(torch.cat((sample_batch.state, self.actor(sample_batch.state)), dim=1))\n",
        "                  )\n",
        "\n",
        "                #Train the actor\n",
        "                actor_optimizer.zero_grad()\n",
        "                actor_loss.backward()\n",
        "                actor_optimizer.step()\n",
        "\n",
        "\n",
        "                #if (((t + 1) % update_after) == 0):\n",
        "                for actor_param, target_actor_param in zip(self.actor.parameters(), self.target_actor.parameters()):\n",
        "                  target_actor_param.data = tau * actor_param.data + (1 - tau) * target_actor_param.data\n",
        "\n",
        "                for critic_param, target_critic_param in zip(self.critic.parameters(), self.target_critic.parameters()):\n",
        "                  target_critic_param.data = tau * critic_param.data + (1 - tau) * target_critic_param.data\n",
        "\n",
        "                if done:\n",
        "                    print(\n",
        "                        \"Completed episode {}/{}\".format(\n",
        "                            e + 1, max_episodes\n",
        "                        )\n",
        "                    )\n",
        "                    break\n",
        "\n",
        "            self.train_rewards_list.append(episode_reward)\n",
        "\n",
        "        self.env.close()\n",
        "        print(self.train_rewards_list)\n",
        "\n",
        "    def plot(self, plot_type):\n",
        "        if (plot_type == \"train\"):\n",
        "            plt.plot(self.train_rewards_list)\n",
        "            plt.show()\n",
        "        elif (plot_type == \"test\"):\n",
        "            plt.plot(self.test_rewards_list)\n",
        "            plt.show()\n",
        "        else:\n",
        "            print(\"\\nInvalid plot type\")"
      ],
      "metadata": {
        "id": "7CZnumvE0baX"
      },
      "id": "7CZnumvE0baX",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gym\n",
        "\n",
        "env = gym.make(\"MountainCarContinuous-v0\")\n",
        "\n",
        "myagent = agent(env)\n",
        "myagent.train(max_episodes=250)\n",
        "myagent.plot(\"train\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "3qpVarsq0bdy",
        "outputId": "695fc960-889d-4dba-ce94-c63b2cc70682"
      },
      "id": "3qpVarsq0bdy",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting Training:\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gym/utils/passive_env_checker.py:241: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
            "  if not isinstance(terminated, (bool, np.bool8)):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completed episode 1/250\n",
            "Completed episode 2/250\n",
            "Completed episode 3/250\n",
            "Completed episode 4/250\n",
            "Completed episode 5/250\n",
            "Completed episode 6/250\n",
            "Completed episode 7/250\n",
            "Completed episode 8/250\n",
            "Completed episode 9/250\n",
            "Completed episode 10/250\n",
            "Completed episode 11/250\n",
            "Completed episode 12/250\n",
            "Completed episode 13/250\n",
            "Completed episode 14/250\n",
            "Completed episode 15/250\n",
            "Completed episode 16/250\n",
            "Completed episode 17/250\n",
            "Completed episode 18/250\n",
            "Completed episode 19/250\n",
            "Completed episode 20/250\n",
            "Completed episode 21/250\n",
            "Completed episode 22/250\n",
            "Completed episode 23/250\n",
            "Completed episode 24/250\n",
            "Completed episode 25/250\n",
            "Completed episode 26/250\n",
            "Completed episode 27/250\n",
            "Completed episode 28/250\n",
            "Completed episode 29/250\n",
            "Completed episode 30/250\n",
            "Completed episode 31/250\n",
            "Completed episode 32/250\n",
            "Completed episode 33/250\n",
            "Completed episode 34/250\n",
            "Completed episode 35/250\n",
            "Completed episode 36/250\n",
            "Completed episode 37/250\n",
            "Completed episode 38/250\n",
            "Completed episode 39/250\n",
            "Completed episode 40/250\n",
            "Completed episode 41/250\n",
            "Completed episode 42/250\n",
            "Completed episode 43/250\n",
            "Completed episode 44/250\n",
            "Completed episode 45/250\n",
            "Completed episode 46/250\n",
            "Completed episode 47/250\n",
            "Completed episode 48/250\n",
            "Completed episode 49/250\n",
            "Completed episode 50/250\n",
            "Completed episode 51/250\n",
            "Completed episode 52/250\n",
            "Completed episode 53/250\n",
            "Completed episode 54/250\n",
            "Completed episode 55/250\n",
            "Completed episode 56/250\n",
            "Completed episode 57/250\n",
            "Completed episode 58/250\n",
            "Completed episode 59/250\n",
            "Completed episode 60/250\n",
            "Completed episode 61/250\n",
            "Completed episode 62/250\n",
            "Completed episode 63/250\n",
            "Completed episode 64/250\n",
            "Completed episode 65/250\n",
            "Completed episode 66/250\n",
            "Completed episode 67/250\n",
            "Completed episode 68/250\n",
            "Completed episode 69/250\n",
            "Completed episode 70/250\n",
            "Completed episode 71/250\n",
            "Completed episode 72/250\n",
            "Completed episode 73/250\n",
            "Completed episode 74/250\n",
            "Completed episode 75/250\n",
            "Completed episode 76/250\n",
            "Completed episode 77/250\n",
            "Completed episode 78/250\n",
            "Completed episode 79/250\n",
            "Completed episode 80/250\n",
            "Completed episode 81/250\n",
            "Completed episode 82/250\n",
            "Completed episode 83/250\n",
            "Completed episode 84/250\n",
            "Completed episode 85/250\n",
            "Completed episode 86/250\n",
            "Completed episode 87/250\n",
            "Completed episode 88/250\n",
            "Completed episode 89/250\n",
            "Completed episode 90/250\n",
            "Completed episode 91/250\n",
            "Completed episode 92/250\n",
            "Completed episode 93/250\n",
            "Completed episode 94/250\n",
            "Completed episode 95/250\n",
            "Completed episode 96/250\n",
            "Completed episode 97/250\n",
            "Completed episode 98/250\n",
            "Completed episode 99/250\n",
            "Completed episode 100/250\n",
            "Completed episode 101/250\n",
            "Completed episode 102/250\n",
            "Completed episode 103/250\n",
            "Completed episode 104/250\n",
            "Completed episode 105/250\n",
            "Completed episode 106/250\n",
            "Completed episode 107/250\n",
            "Completed episode 108/250\n",
            "Completed episode 109/250\n",
            "Completed episode 110/250\n",
            "Completed episode 111/250\n",
            "Completed episode 112/250\n",
            "Completed episode 113/250\n",
            "Completed episode 114/250\n",
            "Completed episode 115/250\n",
            "Completed episode 116/250\n",
            "Completed episode 117/250\n",
            "Completed episode 118/250\n",
            "Completed episode 119/250\n",
            "Completed episode 120/250\n",
            "Completed episode 121/250\n",
            "Completed episode 122/250\n",
            "Completed episode 123/250\n",
            "Completed episode 124/250\n",
            "Completed episode 125/250\n",
            "Completed episode 126/250\n",
            "Completed episode 127/250\n",
            "Completed episode 128/250\n",
            "Completed episode 129/250\n",
            "Completed episode 130/250\n",
            "Completed episode 131/250\n",
            "Completed episode 132/250\n",
            "Completed episode 133/250\n",
            "Completed episode 134/250\n",
            "Completed episode 135/250\n",
            "Completed episode 136/250\n",
            "Completed episode 137/250\n",
            "Completed episode 138/250\n",
            "Completed episode 139/250\n",
            "Completed episode 140/250\n",
            "Completed episode 141/250\n",
            "Completed episode 142/250\n",
            "Completed episode 143/250\n",
            "Completed episode 144/250\n",
            "Completed episode 145/250\n",
            "Completed episode 146/250\n",
            "Completed episode 147/250\n",
            "Completed episode 148/250\n",
            "Completed episode 149/250\n",
            "Completed episode 150/250\n",
            "Completed episode 151/250\n",
            "Completed episode 152/250\n",
            "Completed episode 153/250\n",
            "Completed episode 154/250\n",
            "Completed episode 155/250\n",
            "Completed episode 156/250\n",
            "Completed episode 157/250\n",
            "Completed episode 158/250\n",
            "Completed episode 159/250\n",
            "Completed episode 160/250\n",
            "Completed episode 161/250\n",
            "Completed episode 162/250\n",
            "Completed episode 163/250\n",
            "Completed episode 164/250\n",
            "Completed episode 165/250\n",
            "Completed episode 166/250\n",
            "Completed episode 167/250\n",
            "Completed episode 168/250\n",
            "Completed episode 169/250\n",
            "Completed episode 170/250\n",
            "Completed episode 171/250\n",
            "Completed episode 172/250\n",
            "Completed episode 173/250\n",
            "Completed episode 174/250\n",
            "Completed episode 175/250\n",
            "Completed episode 176/250\n",
            "Completed episode 177/250\n",
            "Completed episode 178/250\n",
            "Completed episode 179/250\n",
            "Completed episode 180/250\n",
            "Completed episode 181/250\n",
            "Completed episode 182/250\n",
            "Completed episode 183/250\n",
            "Completed episode 184/250\n",
            "Completed episode 185/250\n",
            "Completed episode 186/250\n",
            "Completed episode 187/250\n",
            "Completed episode 188/250\n",
            "Completed episode 189/250\n",
            "Completed episode 190/250\n",
            "Completed episode 191/250\n",
            "Completed episode 192/250\n",
            "Completed episode 193/250\n",
            "Completed episode 194/250\n",
            "Completed episode 195/250\n",
            "Completed episode 196/250\n",
            "Completed episode 197/250\n",
            "Completed episode 198/250\n",
            "Completed episode 199/250\n",
            "Completed episode 200/250\n",
            "Completed episode 201/250\n",
            "Completed episode 202/250\n",
            "Completed episode 203/250\n",
            "Completed episode 204/250\n",
            "Completed episode 205/250\n",
            "Completed episode 206/250\n",
            "Completed episode 207/250\n",
            "Completed episode 208/250\n",
            "Completed episode 209/250\n",
            "Completed episode 210/250\n",
            "Completed episode 211/250\n",
            "Completed episode 212/250\n",
            "Completed episode 213/250\n",
            "Completed episode 214/250\n",
            "Completed episode 215/250\n",
            "Completed episode 216/250\n",
            "Completed episode 217/250\n",
            "Completed episode 218/250\n",
            "Completed episode 219/250\n",
            "Completed episode 220/250\n",
            "Completed episode 221/250\n",
            "Completed episode 222/250\n",
            "Completed episode 223/250\n",
            "Completed episode 224/250\n",
            "Completed episode 225/250\n",
            "Completed episode 226/250\n",
            "Completed episode 227/250\n",
            "Completed episode 228/250\n",
            "Completed episode 229/250\n",
            "Completed episode 230/250\n",
            "Completed episode 231/250\n",
            "Completed episode 232/250\n",
            "Completed episode 233/250\n",
            "Completed episode 234/250\n",
            "Completed episode 235/250\n",
            "Completed episode 236/250\n",
            "Completed episode 237/250\n",
            "Completed episode 238/250\n",
            "Completed episode 239/250\n",
            "Completed episode 240/250\n",
            "Completed episode 241/250\n",
            "Completed episode 242/250\n",
            "Completed episode 243/250\n",
            "Completed episode 244/250\n",
            "Completed episode 245/250\n",
            "Completed episode 246/250\n",
            "Completed episode 247/250\n",
            "Completed episode 248/250\n",
            "Completed episode 249/250\n",
            "Completed episode 250/250\n",
            "[-65.60956226070778, -65.85515115872074, 64.51575439406162, -67.11955244718176, 33.24801164758004, -67.42710848397671, -67.67883749260248, -66.61274532946908, -67.46801385691283, -65.90892406683267, -67.51748911795356, -66.14602057558353, -63.704869259328916, -67.16960932515373, -67.4484227562634, 47.86104182295286, -65.10168912539089, -65.6570887127644, 59.508284408720684, -65.14597949546119, -65.2076570370802, -70.53717332264367, 41.30587640285923, -67.24616909828121, 59.296968642421895, 56.24537742816697, -67.4245772234153, -68.64012223036353, 52.87599779853137, 56.20927231988626, 44.353035703941465, 72.04999539181037, 55.4344200939348, 70.2366982968154, -65.48656549920892, 70.92614473263247, -66.52679834489042, 68.34295692102698, -66.78000667991026, 44.45158286688339, 68.42445546776442, 44.69356882761168, 44.01832224885678, 71.73627838783376, 59.78398596820295, 62.49310638174187, 56.08591915249323, 64.44463256891885, 47.50062158494995, 41.26163156503231, 57.22143692720708, 60.183212282960476, 60.411484263514794, 58.553057908567624, 86.11367894797249, 63.43875827285393, 68.76334200970258, 66.44892899033647, 63.04446749716995, 49.90443346421988, 80.47699388646751, 43.28460985629006, 63.767136196957495, 63.4644423049807, 60.05157583588149, 67.4866759155565, 64.71451209830705, 68.26486992318402, 31.73079610257848, 56.700239168688576, 85.34593562948456, 78.05671936567197, 64.09374688975288, 78.65617863313044, 79.88425755248096, 79.15860661368693, 67.05926448837481, 69.0798257844568, 66.1484992774643, 88.371038753008, 78.74157392772028, 71.31851112950719, 49.380798832625636, 64.36497828890646, 79.2271725714527, 74.99770406108006, 46.62181196986648, 69.03630207535915, 83.01287286237431, 54.99123411837849, 78.85997563468682, 62.67158840168054, 74.84145862539046, 83.1299018838674, 65.73843522154547, 69.4832796760013, 57.25095458952421, 56.930234969367284, 43.557559440573165, 58.289599350416495, 73.02558452868836, 58.49424576784754, 63.03272469586012, 62.01793725048549, 78.64683356017457, 88.21770274669471, 82.5924109696996, 78.93627216352793, 83.8879951065542, 71.40870367492799, 70.53818994824461, 73.89061920139471, 78.56542761196911, 65.46901985286897, 71.77501765530315, 80.01200423738334, 81.597824548031, 80.26462511858645, 88.96167164724565, 88.49108292384075, 88.79058548776808, 88.65424328485295, 88.7502582152955, 82.57639637519145, 88.16292056906224, 82.70659753754217, 89.204209183691, 88.00617509007445, 90.22473471399339, 89.0963718226494, 84.91284155578249, 88.71015888171249, 84.27166745579053, 89.44341451168502, 88.77887049750863, 89.40461301458274, 88.88887398433684, 85.81743649497115, 89.01069274078144, 88.85358774481546, 83.0752162175444, 89.95212762421532, 88.36525678879218, 88.46571131559436, 87.76813330175816, 85.34312444603546, 88.48134181856871, 88.0503303592325, 89.82721131272943, 82.89864230795577, 77.70848150467111, 88.79062078665194, 88.3269070085466, 83.13579183352392, 86.64504005850162, 89.33755669447241, 88.99297446571362, 88.93253483285518, 88.96907803196011, 87.94361346971054, 89.27450365394564, 87.74884928576205, 88.4298415830786, 88.109136464472, 87.3024634265674, 88.20244042725336, 88.62951387050656, 86.4242375408216, 88.06113397739855, 88.62368519583774, 89.12837234345231, 88.26993507941329, 88.30667499450551, 87.6837355852033, 88.64584583279056, 87.87428951123803, 88.61264959415817, 88.39154196507256, 92.92781854491517, 88.45246216908671, 88.92173174756616, 89.34038593045477, 85.85611568470254, 80.41980975885002, 89.09344434763875, 88.88698726128347, 89.35250621478036, 89.31490231793146, 87.61001072060023, 87.71863120029369, 88.98695663029982, 89.26475998680816, 88.23229333898047, 89.25388450413122, 87.80708567925224, 88.17625224039764, 88.95473917840675, 88.68855740154173, 83.69862105894511, 88.64608882618069, 88.10963138387616, 87.91515917495757, 83.25822217486471, 74.51045974539727, 88.98596883110083, 87.54512065616248, 76.28608247834288, 83.8401491814911, 87.85115613171331, 90.02392556269719, 86.08794137923837, 83.0180626386654, 87.63908747298935, 88.1035591974685, 89.5259617359798, 88.08917480731131, 87.87075106396722, 81.52457423301537, 83.8636569036772, 87.61954321538539, 79.63933819989454, 88.75506315948178, 87.5515351058933, 82.29092046402431, 72.78102513258689, 88.59045054769024, 82.85780919152026, 83.32056192930845, 89.41461157764022, 88.86200584101233, 87.54298276426152, 75.90713101318164, 89.09024142865755, 84.26761603689567, 88.16120965342037, 84.23074896414029, 88.14318300179434, 89.05847609182582, 88.64849664424042, 76.94230277517828, 87.8869965346653, 88.57402340373719, 87.75372353688772, 82.82530769382794, 88.04009432802147, 67.42790483173653, 78.53625944571255, 76.06749808015992, 41.61581189202197, 81.974949334179]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from stable_baselines3 import DDPG\n",
        "from stable_baselines3.common.env_util import make_vec_env\n",
        "import os\n",
        "import time\n",
        "import numpy as np\n",
        "from stable_baselines3.ddpg.policies import MlpPolicy\n",
        "from stable_baselines3.common.noise import NormalActionNoise, OrnsteinUhlenbeckActionNoise\n"
      ],
      "metadata": {
        "id": "8eiSteSt0jub",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6350311e-940b-44c6-e4f5-796994ff14ca"
      },
      "id": "8eiSteSt0jub",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Saving logs to visulise in Tensorboard, saving models\n",
        "models_dir = f\"models/Mountain-{time.time()}\"\n",
        "logdir = f\"logs/Mountain-{time.time()}\"\n",
        "\n",
        "if not os.path.exists(models_dir):\n",
        "    os.makedirs(models_dir)\n",
        "\n",
        "if not os.path.exists(logdir):\n",
        "    os.makedirs(logdir)"
      ],
      "metadata": {
        "id": "su5FCNIp0jx9"
      },
      "id": "su5FCNIp0jx9",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "f938533a-6867-4d48-8f9c-67a89765701e",
      "metadata": {
        "id": "f938533a-6867-4d48-8f9c-67a89765701e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a323d4e-9879-4e74-ffb0-085ee3314725"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu device\n"
          ]
        }
      ],
      "source": [
        "env = make_vec_env(\"MountainCarContinuous-v0\", n_envs=1)\n",
        "n_actions = env.action_space.shape[-1]\n",
        "action_noise = OrnsteinUhlenbeckActionNoise(mean=np.zeros(n_actions), sigma=float(0.5) * np.ones(n_actions))\n",
        "param_noise = None\n",
        "\n",
        "\n",
        "model = DDPG(MlpPolicy, env, verbose=1, action_noise=action_noise)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Training and saving models along the way\n",
        "TIMESTEPS = 20000\n",
        "for i in range(10):\n",
        "    model.learn(total_timesteps=TIMESTEPS, reset_num_timesteps=False, tb_log_name=\"DDPG\")\n",
        "    model.save(f\"{models_dir}/{TIMESTEPS*i}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "endvQT2Z_AYS",
        "outputId": "6193c750-d411-4f1f-f5ad-1fffcf114c31"
      },
      "id": "endvQT2Z_AYS",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 999      |\n",
            "|    ep_rew_mean     | -35.6    |\n",
            "| time/              |          |\n",
            "|    episodes        | 4        |\n",
            "|    fps             | 37       |\n",
            "|    time_elapsed    | 107      |\n",
            "|    total_timesteps | 3996     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 0.0087   |\n",
            "|    critic_loss     | 1.72e-06 |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 3895     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 999      |\n",
            "|    ep_rew_mean     | -37.5    |\n",
            "| time/              |          |\n",
            "|    episodes        | 8        |\n",
            "|    fps             | 36       |\n",
            "|    time_elapsed    | 218      |\n",
            "|    total_timesteps | 7992     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 0.00661  |\n",
            "|    critic_loss     | 1.37e-06 |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 7891     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 968      |\n",
            "|    ep_rew_mean     | -26.3    |\n",
            "| time/              |          |\n",
            "|    episodes        | 12       |\n",
            "|    fps             | 36       |\n",
            "|    time_elapsed    | 321      |\n",
            "|    total_timesteps | 11611    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -0.0687  |\n",
            "|    critic_loss     | 0.0106   |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 11510    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 876      |\n",
            "|    ep_rew_mean     | -8.27    |\n",
            "| time/              |          |\n",
            "|    episodes        | 16       |\n",
            "|    fps             | 35       |\n",
            "|    time_elapsed    | 391      |\n",
            "|    total_timesteps | 14016    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -1.23    |\n",
            "|    critic_loss     | 0.0167   |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 13915    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 738      |\n",
            "|    ep_rew_mean     | 12.1     |\n",
            "| time/              |          |\n",
            "|    episodes        | 20       |\n",
            "|    fps             | 35       |\n",
            "|    time_elapsed    | 413      |\n",
            "|    total_timesteps | 14762    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -3.19    |\n",
            "|    critic_loss     | 0.0318   |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 14661    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 638      |\n",
            "|    ep_rew_mean     | 25.5     |\n",
            "| time/              |          |\n",
            "|    episodes        | 24       |\n",
            "|    fps             | 35       |\n",
            "|    time_elapsed    | 428      |\n",
            "|    total_timesteps | 15309    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -2.83    |\n",
            "|    critic_loss     | 0.0754   |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 15208    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 580      |\n",
            "|    ep_rew_mean     | 35       |\n",
            "| time/              |          |\n",
            "|    episodes        | 28       |\n",
            "|    fps             | 35       |\n",
            "|    time_elapsed    | 456      |\n",
            "|    total_timesteps | 16234    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -5.76    |\n",
            "|    critic_loss     | 0.122    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 16133    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 529      |\n",
            "|    ep_rew_mean     | 42.2     |\n",
            "| time/              |          |\n",
            "|    episodes        | 32       |\n",
            "|    fps             | 35       |\n",
            "|    time_elapsed    | 476      |\n",
            "|    total_timesteps | 16935    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -4.79    |\n",
            "|    critic_loss     | 0.091    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 16834    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 489      |\n",
            "|    ep_rew_mean     | 47.8     |\n",
            "| time/              |          |\n",
            "|    episodes        | 36       |\n",
            "|    fps             | 35       |\n",
            "|    time_elapsed    | 496      |\n",
            "|    total_timesteps | 17610    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -4.35    |\n",
            "|    critic_loss     | 0.0938   |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 17509    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 460      |\n",
            "|    ep_rew_mean     | 52       |\n",
            "| time/              |          |\n",
            "|    episodes        | 40       |\n",
            "|    fps             | 35       |\n",
            "|    time_elapsed    | 519      |\n",
            "|    total_timesteps | 18381    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -9.34    |\n",
            "|    critic_loss     | 0.108    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 18280    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 436      |\n",
            "|    ep_rew_mean     | 55.1     |\n",
            "| time/              |          |\n",
            "|    episodes        | 44       |\n",
            "|    fps             | 35       |\n",
            "|    time_elapsed    | 542      |\n",
            "|    total_timesteps | 19185    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -13.9    |\n",
            "|    critic_loss     | 0.249    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 19084    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 418      |\n",
            "|    ep_rew_mean     | 58.2     |\n",
            "| time/              |          |\n",
            "|    episodes        | 48       |\n",
            "|    fps             | 38       |\n",
            "|    time_elapsed    | 1        |\n",
            "|    total_timesteps | 20053    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -14.2    |\n",
            "|    critic_loss     | 0.122    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 19952    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 404      |\n",
            "|    ep_rew_mean     | 60.7     |\n",
            "| time/              |          |\n",
            "|    episodes        | 52       |\n",
            "|    fps             | 34       |\n",
            "|    time_elapsed    | 28       |\n",
            "|    total_timesteps | 20987    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -22.3    |\n",
            "|    critic_loss     | 0.235    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 20886    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 384      |\n",
            "|    ep_rew_mean     | 63       |\n",
            "| time/              |          |\n",
            "|    episodes        | 56       |\n",
            "|    fps             | 34       |\n",
            "|    time_elapsed    | 42       |\n",
            "|    total_timesteps | 21478    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -21.5    |\n",
            "|    critic_loss     | 3.97     |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 21377    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 367      |\n",
            "|    ep_rew_mean     | 64.8     |\n",
            "| time/              |          |\n",
            "|    episodes        | 60       |\n",
            "|    fps             | 34       |\n",
            "|    time_elapsed    | 58       |\n",
            "|    total_timesteps | 22016    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -29.6    |\n",
            "|    critic_loss     | 3.24     |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 21915    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 351      |\n",
            "|    ep_rew_mean     | 66.5     |\n",
            "| time/              |          |\n",
            "|    episodes        | 64       |\n",
            "|    fps             | 34       |\n",
            "|    time_elapsed    | 72       |\n",
            "|    total_timesteps | 22491    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -29.8    |\n",
            "|    critic_loss     | 0.449    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 22390    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 336      |\n",
            "|    ep_rew_mean     | 68.1     |\n",
            "| time/              |          |\n",
            "|    episodes        | 68       |\n",
            "|    fps             | 34       |\n",
            "|    time_elapsed    | 82       |\n",
            "|    total_timesteps | 22815    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -32.7    |\n",
            "|    critic_loss     | 0.46     |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 22714    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 321      |\n",
            "|    ep_rew_mean     | 69.5     |\n",
            "| time/              |          |\n",
            "|    episodes        | 72       |\n",
            "|    fps             | 34       |\n",
            "|    time_elapsed    | 90       |\n",
            "|    total_timesteps | 23088    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -33.1    |\n",
            "|    critic_loss     | 0.648    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 22987    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 309      |\n",
            "|    ep_rew_mean     | 70.8     |\n",
            "| time/              |          |\n",
            "|    episodes        | 76       |\n",
            "|    fps             | 34       |\n",
            "|    time_elapsed    | 101      |\n",
            "|    total_timesteps | 23465    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -31      |\n",
            "|    critic_loss     | 0.572    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 23364    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 300      |\n",
            "|    ep_rew_mean     | 71.8     |\n",
            "| time/              |          |\n",
            "|    episodes        | 80       |\n",
            "|    fps             | 34       |\n",
            "|    time_elapsed    | 117      |\n",
            "|    total_timesteps | 23983    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -38      |\n",
            "|    critic_loss     | 0.755    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 23882    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 289      |\n",
            "|    ep_rew_mean     | 72.9     |\n",
            "| time/              |          |\n",
            "|    episodes        | 84       |\n",
            "|    fps             | 34       |\n",
            "|    time_elapsed    | 125      |\n",
            "|    total_timesteps | 24279    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -38.4    |\n",
            "|    critic_loss     | 0.666    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 24178    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 279      |\n",
            "|    ep_rew_mean     | 73.9     |\n",
            "| time/              |          |\n",
            "|    episodes        | 88       |\n",
            "|    fps             | 34       |\n",
            "|    time_elapsed    | 134      |\n",
            "|    total_timesteps | 24588    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -39      |\n",
            "|    critic_loss     | 0.677    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 24487    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 271      |\n",
            "|    ep_rew_mean     | 74.8     |\n",
            "| time/              |          |\n",
            "|    episodes        | 92       |\n",
            "|    fps             | 34       |\n",
            "|    time_elapsed    | 144      |\n",
            "|    total_timesteps | 24900    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -43.6    |\n",
            "|    critic_loss     | 0.61     |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 24799    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 266      |\n",
            "|    ep_rew_mean     | 75.4     |\n",
            "| time/              |          |\n",
            "|    episodes        | 96       |\n",
            "|    fps             | 34       |\n",
            "|    time_elapsed    | 162      |\n",
            "|    total_timesteps | 25537    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -47.9    |\n",
            "|    critic_loss     | 0.713    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 25436    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 259      |\n",
            "|    ep_rew_mean     | 76.1     |\n",
            "| time/              |          |\n",
            "|    episodes        | 100      |\n",
            "|    fps             | 34       |\n",
            "|    time_elapsed    | 174      |\n",
            "|    total_timesteps | 25939    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -50      |\n",
            "|    critic_loss     | 0.455    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 25838    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 224      |\n",
            "|    ep_rew_mean     | 81.2     |\n",
            "| time/              |          |\n",
            "|    episodes        | 104      |\n",
            "|    fps             | 34       |\n",
            "|    time_elapsed    | 187      |\n",
            "|    total_timesteps | 26368    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -50.7    |\n",
            "|    critic_loss     | 0.684    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 26267    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 187      |\n",
            "|    ep_rew_mean     | 86.5     |\n",
            "| time/              |          |\n",
            "|    episodes        | 108      |\n",
            "|    fps             | 33       |\n",
            "|    time_elapsed    | 196      |\n",
            "|    total_timesteps | 26672    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -52      |\n",
            "|    critic_loss     | 0.563    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 26571    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 154      |\n",
            "|    ep_rew_mean     | 90.4     |\n",
            "| time/              |          |\n",
            "|    episodes        | 112      |\n",
            "|    fps             | 34       |\n",
            "|    time_elapsed    | 204      |\n",
            "|    total_timesteps | 26980    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -57.2    |\n",
            "|    critic_loss     | 0.53     |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 26879    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 133      |\n",
            "|    ep_rew_mean     | 92.3     |\n",
            "| time/              |          |\n",
            "|    episodes        | 116      |\n",
            "|    fps             | 34       |\n",
            "|    time_elapsed    | 214      |\n",
            "|    total_timesteps | 27301    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -56.9    |\n",
            "|    critic_loss     | 0.581    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 27200    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 128      |\n",
            "|    ep_rew_mean     | 92.3     |\n",
            "| time/              |          |\n",
            "|    episodes        | 120      |\n",
            "|    fps             | 34       |\n",
            "|    time_elapsed    | 223      |\n",
            "|    total_timesteps | 27605    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -58.3    |\n",
            "|    critic_loss     | 0.591    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 27504    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 126      |\n",
            "|    ep_rew_mean     | 92.4     |\n",
            "| time/              |          |\n",
            "|    episodes        | 124      |\n",
            "|    fps             | 34       |\n",
            "|    time_elapsed    | 231      |\n",
            "|    total_timesteps | 27897    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -59.7    |\n",
            "|    critic_loss     | 0.513    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 27796    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 120      |\n",
            "|    ep_rew_mean     | 92.5     |\n",
            "| time/              |          |\n",
            "|    episodes        | 128      |\n",
            "|    fps             | 34       |\n",
            "|    time_elapsed    | 241      |\n",
            "|    total_timesteps | 28204    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -62.4    |\n",
            "|    critic_loss     | 0.505    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 28103    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 116      |\n",
            "|    ep_rew_mean     | 92.5     |\n",
            "| time/              |          |\n",
            "|    episodes        | 132      |\n",
            "|    fps             | 33       |\n",
            "|    time_elapsed    | 250      |\n",
            "|    total_timesteps | 28523    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -65      |\n",
            "|    critic_loss     | 0.473    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 28422    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 113      |\n",
            "|    ep_rew_mean     | 92.5     |\n",
            "| time/              |          |\n",
            "|    episodes        | 136      |\n",
            "|    fps             | 33       |\n",
            "|    time_elapsed    | 262      |\n",
            "|    total_timesteps | 28918    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -65      |\n",
            "|    critic_loss     | 0.509    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 28817    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 108      |\n",
            "|    ep_rew_mean     | 92.7     |\n",
            "| time/              |          |\n",
            "|    episodes        | 140      |\n",
            "|    fps             | 34       |\n",
            "|    time_elapsed    | 270      |\n",
            "|    total_timesteps | 29225    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -65.9    |\n",
            "|    critic_loss     | 0.394    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 29124    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 103      |\n",
            "|    ep_rew_mean     | 93       |\n",
            "| time/              |          |\n",
            "|    episodes        | 144      |\n",
            "|    fps             | 34       |\n",
            "|    time_elapsed    | 279      |\n",
            "|    total_timesteps | 29525    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -67.9    |\n",
            "|    critic_loss     | 0.368    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 29424    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 97.8     |\n",
            "|    ep_rew_mean     | 93.1     |\n",
            "| time/              |          |\n",
            "|    episodes        | 148      |\n",
            "|    fps             | 34       |\n",
            "|    time_elapsed    | 289      |\n",
            "|    total_timesteps | 29838    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -67.6    |\n",
            "|    critic_loss     | 0.408    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 29737    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 91.6     |\n",
            "|    ep_rew_mean     | 93.2     |\n",
            "| time/              |          |\n",
            "|    episodes        | 152      |\n",
            "|    fps             | 34       |\n",
            "|    time_elapsed    | 297      |\n",
            "|    total_timesteps | 30148    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -68.3    |\n",
            "|    critic_loss     | 0.532    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 30047    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 89.7     |\n",
            "|    ep_rew_mean     | 93.2     |\n",
            "| time/              |          |\n",
            "|    episodes        | 156      |\n",
            "|    fps             | 34       |\n",
            "|    time_elapsed    | 306      |\n",
            "|    total_timesteps | 30446    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -67      |\n",
            "|    critic_loss     | 0.805    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 30345    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 89.1     |\n",
            "|    ep_rew_mean     | 93.3     |\n",
            "| time/              |          |\n",
            "|    episodes        | 160      |\n",
            "|    fps             | 34       |\n",
            "|    time_elapsed    | 320      |\n",
            "|    total_timesteps | 30927    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -68.2    |\n",
            "|    critic_loss     | 0.279    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 30826    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 87.3     |\n",
            "|    ep_rew_mean     | 93.4     |\n",
            "| time/              |          |\n",
            "|    episodes        | 164      |\n",
            "|    fps             | 34       |\n",
            "|    time_elapsed    | 329      |\n",
            "|    total_timesteps | 31220    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -68.2    |\n",
            "|    critic_loss     | 0.239    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 31119    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 87.1     |\n",
            "|    ep_rew_mean     | 93.4     |\n",
            "| time/              |          |\n",
            "|    episodes        | 168      |\n",
            "|    fps             | 34       |\n",
            "|    time_elapsed    | 338      |\n",
            "|    total_timesteps | 31525    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -68.2    |\n",
            "|    critic_loss     | 0.274    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 31424    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 87.5     |\n",
            "|    ep_rew_mean     | 93.4     |\n",
            "| time/              |          |\n",
            "|    episodes        | 172      |\n",
            "|    fps             | 34       |\n",
            "|    time_elapsed    | 347      |\n",
            "|    total_timesteps | 31838    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -67.3    |\n",
            "|    critic_loss     | 0.28     |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 31737    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 87       |\n",
            "|    ep_rew_mean     | 93.3     |\n",
            "| time/              |          |\n",
            "|    episodes        | 176      |\n",
            "|    fps             | 33       |\n",
            "|    time_elapsed    | 357      |\n",
            "|    total_timesteps | 32167    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -68.5    |\n",
            "|    critic_loss     | 0.284    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 32066    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 85.1     |\n",
            "|    ep_rew_mean     | 93.4     |\n",
            "| time/              |          |\n",
            "|    episodes        | 180      |\n",
            "|    fps             | 34       |\n",
            "|    time_elapsed    | 366      |\n",
            "|    total_timesteps | 32489    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -66.1    |\n",
            "|    critic_loss     | 0.263    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 32388    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 85.1     |\n",
            "|    ep_rew_mean     | 93.4     |\n",
            "| time/              |          |\n",
            "|    episodes        | 184      |\n",
            "|    fps             | 34       |\n",
            "|    time_elapsed    | 376      |\n",
            "|    total_timesteps | 32792    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -66.6    |\n",
            "|    critic_loss     | 0.502    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 32691    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 85       |\n",
            "|    ep_rew_mean     | 93.4     |\n",
            "| time/              |          |\n",
            "|    episodes        | 188      |\n",
            "|    fps             | 33       |\n",
            "|    time_elapsed    | 385      |\n",
            "|    total_timesteps | 33083    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -67      |\n",
            "|    critic_loss     | 0.256    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 32982    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 84.6     |\n",
            "|    ep_rew_mean     | 93.3     |\n",
            "| time/              |          |\n",
            "|    episodes        | 192      |\n",
            "|    fps             | 34       |\n",
            "|    time_elapsed    | 392      |\n",
            "|    total_timesteps | 33363    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -66.9    |\n",
            "|    critic_loss     | 0.177    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 33262    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 82.1     |\n",
            "|    ep_rew_mean     | 93.5     |\n",
            "| time/              |          |\n",
            "|    episodes        | 196      |\n",
            "|    fps             | 34       |\n",
            "|    time_elapsed    | 404      |\n",
            "|    total_timesteps | 33743    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -66.8    |\n",
            "|    critic_loss     | 0.226    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 33642    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 82.3     |\n",
            "|    ep_rew_mean     | 93.5     |\n",
            "| time/              |          |\n",
            "|    episodes        | 200      |\n",
            "|    fps             | 33       |\n",
            "|    time_elapsed    | 417      |\n",
            "|    total_timesteps | 34167    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -68.3    |\n",
            "|    critic_loss     | 0.201    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 34066    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 82.5     |\n",
            "|    ep_rew_mean     | 93.5     |\n",
            "| time/              |          |\n",
            "|    episodes        | 204      |\n",
            "|    fps             | 33       |\n",
            "|    time_elapsed    | 430      |\n",
            "|    total_timesteps | 34618    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -66.1    |\n",
            "|    critic_loss     | 0.169    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 34517    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 83.6     |\n",
            "|    ep_rew_mean     | 93.4     |\n",
            "| time/              |          |\n",
            "|    episodes        | 208      |\n",
            "|    fps             | 33       |\n",
            "|    time_elapsed    | 442      |\n",
            "|    total_timesteps | 35031    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -65.8    |\n",
            "|    critic_loss     | 0.175    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 34930    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 84.2     |\n",
            "|    ep_rew_mean     | 93.4     |\n",
            "| time/              |          |\n",
            "|    episodes        | 212      |\n",
            "|    fps             | 33       |\n",
            "|    time_elapsed    | 453      |\n",
            "|    total_timesteps | 35398    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -66.3    |\n",
            "|    critic_loss     | 0.198    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 35297    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 85.3     |\n",
            "|    ep_rew_mean     | 93.4     |\n",
            "| time/              |          |\n",
            "|    episodes        | 216      |\n",
            "|    fps             | 33       |\n",
            "|    time_elapsed    | 466      |\n",
            "|    total_timesteps | 35828    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -66.7    |\n",
            "|    critic_loss     | 0.203    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 35727    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 86.4     |\n",
            "|    ep_rew_mean     | 93.2     |\n",
            "| time/              |          |\n",
            "|    episodes        | 220      |\n",
            "|    fps             | 33       |\n",
            "|    time_elapsed    | 479      |\n",
            "|    total_timesteps | 36246    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -66.9    |\n",
            "|    critic_loss     | 0.224    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 36145    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 97.9     |\n",
            "|    ep_rew_mean     | 91.5     |\n",
            "| time/              |          |\n",
            "|    episodes        | 224      |\n",
            "|    fps             | 33       |\n",
            "|    time_elapsed    | 523      |\n",
            "|    total_timesteps | 37687    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -65.6    |\n",
            "|    critic_loss     | 0.246    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 37586    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 99.5     |\n",
            "|    ep_rew_mean     | 91.4     |\n",
            "| time/              |          |\n",
            "|    episodes        | 228      |\n",
            "|    fps             | 33       |\n",
            "|    time_elapsed    | 537      |\n",
            "|    total_timesteps | 38151    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -65.6    |\n",
            "|    critic_loss     | 0.197    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 38050    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 101      |\n",
            "|    ep_rew_mean     | 91.3     |\n",
            "| time/              |          |\n",
            "|    episodes        | 232      |\n",
            "|    fps             | 33       |\n",
            "|    time_elapsed    | 551      |\n",
            "|    total_timesteps | 38612    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -64.8    |\n",
            "|    critic_loss     | 0.214    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 38511    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 101      |\n",
            "|    ep_rew_mean     | 91.2     |\n",
            "| time/              |          |\n",
            "|    episodes        | 236      |\n",
            "|    fps             | 33       |\n",
            "|    time_elapsed    | 564      |\n",
            "|    total_timesteps | 39036    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -64.5    |\n",
            "|    critic_loss     | 0.257    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 38935    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 102      |\n",
            "|    ep_rew_mean     | 91.2     |\n",
            "| time/              |          |\n",
            "|    episodes        | 240      |\n",
            "|    fps             | 33       |\n",
            "|    time_elapsed    | 576      |\n",
            "|    total_timesteps | 39448    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -62.8    |\n",
            "|    critic_loss     | 0.246    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 39347    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 103      |\n",
            "|    ep_rew_mean     | 91.1     |\n",
            "| time/              |          |\n",
            "|    episodes        | 244      |\n",
            "|    fps             | 33       |\n",
            "|    time_elapsed    | 588      |\n",
            "|    total_timesteps | 39851    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -62.9    |\n",
            "|    critic_loss     | 0.214    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 39750    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 104      |\n",
            "|    ep_rew_mean     | 91       |\n",
            "| time/              |          |\n",
            "|    episodes        | 248      |\n",
            "|    fps             | 29       |\n",
            "|    time_elapsed    | 7        |\n",
            "|    total_timesteps | 40210    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -61.8    |\n",
            "|    critic_loss     | 0.332    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 40109    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 105      |\n",
            "|    ep_rew_mean     | 91       |\n",
            "| time/              |          |\n",
            "|    episodes        | 252      |\n",
            "|    fps             | 32       |\n",
            "|    time_elapsed    | 18       |\n",
            "|    total_timesteps | 40603    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -62.8    |\n",
            "|    critic_loss     | 0.233    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 40502    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 105      |\n",
            "|    ep_rew_mean     | 90.9     |\n",
            "| time/              |          |\n",
            "|    episodes        | 256      |\n",
            "|    fps             | 32       |\n",
            "|    time_elapsed    | 28       |\n",
            "|    total_timesteps | 40940    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -63.9    |\n",
            "|    critic_loss     | 0.212    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 40839    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 104      |\n",
            "|    ep_rew_mean     | 91       |\n",
            "| time/              |          |\n",
            "|    episodes        | 260      |\n",
            "|    fps             | 32       |\n",
            "|    time_elapsed    | 39       |\n",
            "|    total_timesteps | 41291    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -64.1    |\n",
            "|    critic_loss     | 0.27     |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 41190    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 106      |\n",
            "|    ep_rew_mean     | 90.9     |\n",
            "| time/              |          |\n",
            "|    episodes        | 264      |\n",
            "|    fps             | 32       |\n",
            "|    time_elapsed    | 54       |\n",
            "|    total_timesteps | 41794    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -62.9    |\n",
            "|    critic_loss     | 0.186    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 41693    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 105      |\n",
            "|    ep_rew_mean     | 90.9     |\n",
            "| time/              |          |\n",
            "|    episodes        | 268      |\n",
            "|    fps             | 32       |\n",
            "|    time_elapsed    | 63       |\n",
            "|    total_timesteps | 42067    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -61.3    |\n",
            "|    critic_loss     | 0.185    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 41966    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 105      |\n",
            "|    ep_rew_mean     | 90.9     |\n",
            "| time/              |          |\n",
            "|    episodes        | 272      |\n",
            "|    fps             | 32       |\n",
            "|    time_elapsed    | 71       |\n",
            "|    total_timesteps | 42347    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -61.4    |\n",
            "|    critic_loss     | 0.222    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 42246    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 105      |\n",
            "|    ep_rew_mean     | 90.9     |\n",
            "| time/              |          |\n",
            "|    episodes        | 276      |\n",
            "|    fps             | 32       |\n",
            "|    time_elapsed    | 82       |\n",
            "|    total_timesteps | 42687    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -62.7    |\n",
            "|    critic_loss     | 0.227    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 42586    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 105      |\n",
            "|    ep_rew_mean     | 90.9     |\n",
            "| time/              |          |\n",
            "|    episodes        | 280      |\n",
            "|    fps             | 32       |\n",
            "|    time_elapsed    | 90       |\n",
            "|    total_timesteps | 42954    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -63.7    |\n",
            "|    critic_loss     | 0.23     |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 42853    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 105      |\n",
            "|    ep_rew_mean     | 90.9     |\n",
            "| time/              |          |\n",
            "|    episodes        | 284      |\n",
            "|    fps             | 32       |\n",
            "|    time_elapsed    | 101      |\n",
            "|    total_timesteps | 43323    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -62.1    |\n",
            "|    critic_loss     | 0.245    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 43222    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 105      |\n",
            "|    ep_rew_mean     | 90.9     |\n",
            "| time/              |          |\n",
            "|    episodes        | 288      |\n",
            "|    fps             | 32       |\n",
            "|    time_elapsed    | 110      |\n",
            "|    total_timesteps | 43619    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -62      |\n",
            "|    critic_loss     | 0.167    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 43518    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 105      |\n",
            "|    ep_rew_mean     | 91       |\n",
            "| time/              |          |\n",
            "|    episodes        | 292      |\n",
            "|    fps             | 32       |\n",
            "|    time_elapsed    | 119      |\n",
            "|    total_timesteps | 43905    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -62.3    |\n",
            "|    critic_loss     | 0.22     |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 43804    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 105      |\n",
            "|    ep_rew_mean     | 90.9     |\n",
            "| time/              |          |\n",
            "|    episodes        | 296      |\n",
            "|    fps             | 32       |\n",
            "|    time_elapsed    | 131      |\n",
            "|    total_timesteps | 44283    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -61.5    |\n",
            "|    critic_loss     | 0.279    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 44182    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 104      |\n",
            "|    ep_rew_mean     | 91       |\n",
            "| time/              |          |\n",
            "|    episodes        | 300      |\n",
            "|    fps             | 32       |\n",
            "|    time_elapsed    | 140      |\n",
            "|    total_timesteps | 44571    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -62.1    |\n",
            "|    critic_loss     | 0.159    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 44470    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 103      |\n",
            "|    ep_rew_mean     | 91       |\n",
            "| time/              |          |\n",
            "|    episodes        | 304      |\n",
            "|    fps             | 32       |\n",
            "|    time_elapsed    | 149      |\n",
            "|    total_timesteps | 44869    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -61.2    |\n",
            "|    critic_loss     | 0.202    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 44768    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 101      |\n",
            "|    ep_rew_mean     | 91.1     |\n",
            "| time/              |          |\n",
            "|    episodes        | 308      |\n",
            "|    fps             | 32       |\n",
            "|    time_elapsed    | 158      |\n",
            "|    total_timesteps | 45154    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -62.1    |\n",
            "|    critic_loss     | 0.213    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 45053    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 101      |\n",
            "|    ep_rew_mean     | 91.1     |\n",
            "| time/              |          |\n",
            "|    episodes        | 312      |\n",
            "|    fps             | 32       |\n",
            "|    time_elapsed    | 169      |\n",
            "|    total_timesteps | 45529    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -62.1    |\n",
            "|    critic_loss     | 0.156    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 45428    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 99.7     |\n",
            "|    ep_rew_mean     | 91.2     |\n",
            "| time/              |          |\n",
            "|    episodes        | 316      |\n",
            "|    fps             | 32       |\n",
            "|    time_elapsed    | 177      |\n",
            "|    total_timesteps | 45800    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -60.9    |\n",
            "|    critic_loss     | 0.171    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 45699    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 100      |\n",
            "|    ep_rew_mean     | 91.3     |\n",
            "| time/              |          |\n",
            "|    episodes        | 320      |\n",
            "|    fps             | 32       |\n",
            "|    time_elapsed    | 192      |\n",
            "|    total_timesteps | 46258    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -61.7    |\n",
            "|    critic_loss     | 0.172    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 46157    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 89.1     |\n",
            "|    ep_rew_mean     | 93       |\n",
            "| time/              |          |\n",
            "|    episodes        | 324      |\n",
            "|    fps             | 32       |\n",
            "|    time_elapsed    | 202      |\n",
            "|    total_timesteps | 46599    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -60.9    |\n",
            "|    critic_loss     | 0.241    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 46498    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 87.4     |\n",
            "|    ep_rew_mean     | 93.2     |\n",
            "| time/              |          |\n",
            "|    episodes        | 328      |\n",
            "|    fps             | 32       |\n",
            "|    time_elapsed    | 212      |\n",
            "|    total_timesteps | 46890    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -62      |\n",
            "|    critic_loss     | 0.224    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 46789    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 87.2     |\n",
            "|    ep_rew_mean     | 93.3     |\n",
            "| time/              |          |\n",
            "|    episodes        | 332      |\n",
            "|    fps             | 32       |\n",
            "|    time_elapsed    | 225      |\n",
            "|    total_timesteps | 47334    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -62.8    |\n",
            "|    critic_loss     | 0.206    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 47233    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 89.2     |\n",
            "|    ep_rew_mean     | 93.2     |\n",
            "| time/              |          |\n",
            "|    episodes        | 336      |\n",
            "|    fps             | 32       |\n",
            "|    time_elapsed    | 244      |\n",
            "|    total_timesteps | 47959    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -62.4    |\n",
            "|    critic_loss     | 0.159    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 47858    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 88       |\n",
            "|    ep_rew_mean     | 93.3     |\n",
            "| time/              |          |\n",
            "|    episodes        | 340      |\n",
            "|    fps             | 32       |\n",
            "|    time_elapsed    | 254      |\n",
            "|    total_timesteps | 48249    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -61.8    |\n",
            "|    critic_loss     | 0.176    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 48148    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 86.8     |\n",
            "|    ep_rew_mean     | 93.4     |\n",
            "| time/              |          |\n",
            "|    episodes        | 344      |\n",
            "|    fps             | 32       |\n",
            "|    time_elapsed    | 263      |\n",
            "|    total_timesteps | 48527    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -62.6    |\n",
            "|    critic_loss     | 0.169    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 48426    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 85.9     |\n",
            "|    ep_rew_mean     | 93.5     |\n",
            "| time/              |          |\n",
            "|    episodes        | 348      |\n",
            "|    fps             | 32       |\n",
            "|    time_elapsed    | 271      |\n",
            "|    total_timesteps | 48804    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -60.9    |\n",
            "|    critic_loss     | 0.151    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 48703    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 84.9     |\n",
            "|    ep_rew_mean     | 93.6     |\n",
            "| time/              |          |\n",
            "|    episodes        | 352      |\n",
            "|    fps             | 32       |\n",
            "|    time_elapsed    | 280      |\n",
            "|    total_timesteps | 49089    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -62.5    |\n",
            "|    critic_loss     | 0.196    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 48988    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 84.4     |\n",
            "|    ep_rew_mean     | 93.7     |\n",
            "| time/              |          |\n",
            "|    episodes        | 356      |\n",
            "|    fps             | 32       |\n",
            "|    time_elapsed    | 289      |\n",
            "|    total_timesteps | 49378    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -61.6    |\n",
            "|    critic_loss     | 0.338    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 49277    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 84.5     |\n",
            "|    ep_rew_mean     | 93.7     |\n",
            "| time/              |          |\n",
            "|    episodes        | 360      |\n",
            "|    fps             | 32       |\n",
            "|    time_elapsed    | 301      |\n",
            "|    total_timesteps | 49738    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -62.6    |\n",
            "|    critic_loss     | 0.21     |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 49637    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 82.3     |\n",
            "|    ep_rew_mean     | 93.8     |\n",
            "| time/              |          |\n",
            "|    episodes        | 364      |\n",
            "|    fps             | 32       |\n",
            "|    time_elapsed    | 309      |\n",
            "|    total_timesteps | 50025    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -63      |\n",
            "|    critic_loss     | 0.129    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 49924    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 83.1     |\n",
            "|    ep_rew_mean     | 93.8     |\n",
            "| time/              |          |\n",
            "|    episodes        | 368      |\n",
            "|    fps             | 32       |\n",
            "|    time_elapsed    | 321      |\n",
            "|    total_timesteps | 50380    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -62.3    |\n",
            "|    critic_loss     | 0.159    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 50279    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 91.6     |\n",
            "|    ep_rew_mean     | 93.3     |\n",
            "| time/              |          |\n",
            "|    episodes        | 372      |\n",
            "|    fps             | 32       |\n",
            "|    time_elapsed    | 357      |\n",
            "|    total_timesteps | 51511    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -62.5    |\n",
            "|    critic_loss     | 0.265    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 51410    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 99.8     |\n",
            "|    ep_rew_mean     | 92.8     |\n",
            "| time/              |          |\n",
            "|    episodes        | 376      |\n",
            "|    fps             | 32       |\n",
            "|    time_elapsed    | 394      |\n",
            "|    total_timesteps | 52663    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -62.6    |\n",
            "|    critic_loss     | 0.118    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 52562    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 99.9     |\n",
            "|    ep_rew_mean     | 92.8     |\n",
            "| time/              |          |\n",
            "|    episodes        | 380      |\n",
            "|    fps             | 32       |\n",
            "|    time_elapsed    | 403      |\n",
            "|    total_timesteps | 52946    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -64      |\n",
            "|    critic_loss     | 0.156    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 52845    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 99       |\n",
            "|    ep_rew_mean     | 92.8     |\n",
            "| time/              |          |\n",
            "|    episodes        | 384      |\n",
            "|    fps             | 32       |\n",
            "|    time_elapsed    | 412      |\n",
            "|    total_timesteps | 53224    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -64.1    |\n",
            "|    critic_loss     | 0.12     |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 53123    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 99       |\n",
            "|    ep_rew_mean     | 92.9     |\n",
            "| time/              |          |\n",
            "|    episodes        | 388      |\n",
            "|    fps             | 31       |\n",
            "|    time_elapsed    | 422      |\n",
            "|    total_timesteps | 53515    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -64.5    |\n",
            "|    critic_loss     | 0.126    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 53414    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 99.5     |\n",
            "|    ep_rew_mean     | 92.9     |\n",
            "| time/              |          |\n",
            "|    episodes        | 392      |\n",
            "|    fps             | 31       |\n",
            "|    time_elapsed    | 433      |\n",
            "|    total_timesteps | 53859    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -63.2    |\n",
            "|    critic_loss     | 0.205    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 53758    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 99.3     |\n",
            "|    ep_rew_mean     | 92.9     |\n",
            "| time/              |          |\n",
            "|    episodes        | 396      |\n",
            "|    fps             | 31       |\n",
            "|    time_elapsed    | 444      |\n",
            "|    total_timesteps | 54214    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -62.4    |\n",
            "|    critic_loss     | 0.164    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 54113    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 99.9     |\n",
            "|    ep_rew_mean     | 92.9     |\n",
            "| time/              |          |\n",
            "|    episodes        | 400      |\n",
            "|    fps             | 31       |\n",
            "|    time_elapsed    | 456      |\n",
            "|    total_timesteps | 54561    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -63.5    |\n",
            "|    critic_loss     | 0.186    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 54460    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 99.7     |\n",
            "|    ep_rew_mean     | 92.9     |\n",
            "| time/              |          |\n",
            "|    episodes        | 404      |\n",
            "|    fps             | 31       |\n",
            "|    time_elapsed    | 465      |\n",
            "|    total_timesteps | 54835    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -64.3    |\n",
            "|    critic_loss     | 0.143    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 54734    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 103      |\n",
            "|    ep_rew_mean     | 92.8     |\n",
            "| time/              |          |\n",
            "|    episodes        | 408      |\n",
            "|    fps             | 31       |\n",
            "|    time_elapsed    | 484      |\n",
            "|    total_timesteps | 55434    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -63.6    |\n",
            "|    critic_loss     | 0.141    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 55333    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 102      |\n",
            "|    ep_rew_mean     | 92.9     |\n",
            "| time/              |          |\n",
            "|    episodes        | 412      |\n",
            "|    fps             | 31       |\n",
            "|    time_elapsed    | 494      |\n",
            "|    total_timesteps | 55724    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -64.5    |\n",
            "|    critic_loss     | 0.13     |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 55623    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 102      |\n",
            "|    ep_rew_mean     | 92.9     |\n",
            "| time/              |          |\n",
            "|    episodes        | 416      |\n",
            "|    fps             | 31       |\n",
            "|    time_elapsed    | 504      |\n",
            "|    total_timesteps | 56023    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -64.9    |\n",
            "|    critic_loss     | 0.188    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 55922    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 101      |\n",
            "|    ep_rew_mean     | 92.9     |\n",
            "| time/              |          |\n",
            "|    episodes        | 420      |\n",
            "|    fps             | 31       |\n",
            "|    time_elapsed    | 516      |\n",
            "|    total_timesteps | 56385    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -63.4    |\n",
            "|    critic_loss     | 0.11     |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 56284    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 101      |\n",
            "|    ep_rew_mean     | 92.9     |\n",
            "| time/              |          |\n",
            "|    episodes        | 424      |\n",
            "|    fps             | 31       |\n",
            "|    time_elapsed    | 525      |\n",
            "|    total_timesteps | 56666    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -65.4    |\n",
            "|    critic_loss     | 0.171    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 56565    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 102      |\n",
            "|    ep_rew_mean     | 92.9     |\n",
            "| time/              |          |\n",
            "|    episodes        | 428      |\n",
            "|    fps             | 31       |\n",
            "|    time_elapsed    | 541      |\n",
            "|    total_timesteps | 57133    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -64.4    |\n",
            "|    critic_loss     | 0.145    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 57032    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 101      |\n",
            "|    ep_rew_mean     | 92.9     |\n",
            "| time/              |          |\n",
            "|    episodes        | 432      |\n",
            "|    fps             | 31       |\n",
            "|    time_elapsed    | 550      |\n",
            "|    total_timesteps | 57423    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -64.5    |\n",
            "|    critic_loss     | 0.152    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 57322    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 98.4     |\n",
            "|    ep_rew_mean     | 93.1     |\n",
            "| time/              |          |\n",
            "|    episodes        | 436      |\n",
            "|    fps             | 31       |\n",
            "|    time_elapsed    | 562      |\n",
            "|    total_timesteps | 57799    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -63.9    |\n",
            "|    critic_loss     | 0.11     |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 57698    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 98.4     |\n",
            "|    ep_rew_mean     | 93.1     |\n",
            "| time/              |          |\n",
            "|    episodes        | 440      |\n",
            "|    fps             | 31       |\n",
            "|    time_elapsed    | 572      |\n",
            "|    total_timesteps | 58091    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -64.7    |\n",
            "|    critic_loss     | 0.115    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 57990    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 98.4     |\n",
            "|    ep_rew_mean     | 93.1     |\n",
            "| time/              |          |\n",
            "|    episodes        | 444      |\n",
            "|    fps             | 31       |\n",
            "|    time_elapsed    | 582      |\n",
            "|    total_timesteps | 58371    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -65.7    |\n",
            "|    critic_loss     | 0.129    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 58270    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 100      |\n",
            "|    ep_rew_mean     | 93       |\n",
            "| time/              |          |\n",
            "|    episodes        | 448      |\n",
            "|    fps             | 31       |\n",
            "|    time_elapsed    | 597      |\n",
            "|    total_timesteps | 58818    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -65.4    |\n",
            "|    critic_loss     | 0.156    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 58717    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 100      |\n",
            "|    ep_rew_mean     | 93       |\n",
            "| time/              |          |\n",
            "|    episodes        | 452      |\n",
            "|    fps             | 31       |\n",
            "|    time_elapsed    | 606      |\n",
            "|    total_timesteps | 59101    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -65.9    |\n",
            "|    critic_loss     | 0.138    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 59000    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 100      |\n",
            "|    ep_rew_mean     | 93       |\n",
            "| time/              |          |\n",
            "|    episodes        | 456      |\n",
            "|    fps             | 31       |\n",
            "|    time_elapsed    | 616      |\n",
            "|    total_timesteps | 59411    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -66.6    |\n",
            "|    critic_loss     | 0.141    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 59310    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 99.5     |\n",
            "|    ep_rew_mean     | 93       |\n",
            "| time/              |          |\n",
            "|    episodes        | 460      |\n",
            "|    fps             | 31       |\n",
            "|    time_elapsed    | 626      |\n",
            "|    total_timesteps | 59692    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -65.4    |\n",
            "|    critic_loss     | 0.206    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 59591    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 99.5     |\n",
            "|    ep_rew_mean     | 93       |\n",
            "| time/              |          |\n",
            "|    episodes        | 464      |\n",
            "|    fps             | 31       |\n",
            "|    time_elapsed    | 635      |\n",
            "|    total_timesteps | 59970    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -63.8    |\n",
            "|    critic_loss     | 0.232    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 59869    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 99.3     |\n",
            "|    ep_rew_mean     | 93       |\n",
            "| time/              |          |\n",
            "|    episodes        | 468      |\n",
            "|    fps             | 31       |\n",
            "|    time_elapsed    | 9        |\n",
            "|    total_timesteps | 60309    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -66.4    |\n",
            "|    critic_loss     | 0.156    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 60208    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 92.2     |\n",
            "|    ep_rew_mean     | 93.5     |\n",
            "| time/              |          |\n",
            "|    episodes        | 472      |\n",
            "|    fps             | 30       |\n",
            "|    time_elapsed    | 24       |\n",
            "|    total_timesteps | 60731    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -66.4    |\n",
            "|    critic_loss     | 0.144    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 60630    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 84.2     |\n",
            "|    ep_rew_mean     | 94       |\n",
            "| time/              |          |\n",
            "|    episodes        | 476      |\n",
            "|    fps             | 30       |\n",
            "|    time_elapsed    | 35       |\n",
            "|    total_timesteps | 61080    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -66.2    |\n",
            "|    critic_loss     | 0.188    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 60979    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 84.1     |\n",
            "|    ep_rew_mean     | 94       |\n",
            "| time/              |          |\n",
            "|    episodes        | 480      |\n",
            "|    fps             | 30       |\n",
            "|    time_elapsed    | 45       |\n",
            "|    total_timesteps | 61357    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -66.5    |\n",
            "|    critic_loss     | 0.169    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 61256    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 86       |\n",
            "|    ep_rew_mean     | 93.9     |\n",
            "| time/              |          |\n",
            "|    episodes        | 484      |\n",
            "|    fps             | 30       |\n",
            "|    time_elapsed    | 60       |\n",
            "|    total_timesteps | 61820    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -65.7    |\n",
            "|    critic_loss     | 0.145    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 61719    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 86.7     |\n",
            "|    ep_rew_mean     | 93.9     |\n",
            "| time/              |          |\n",
            "|    episodes        | 488      |\n",
            "|    fps             | 29       |\n",
            "|    time_elapsed    | 72       |\n",
            "|    total_timesteps | 62180    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -66.8    |\n",
            "|    critic_loss     | 0.187    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 62079    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 86.7     |\n",
            "|    ep_rew_mean     | 93.9     |\n",
            "| time/              |          |\n",
            "|    episodes        | 492      |\n",
            "|    fps             | 29       |\n",
            "|    time_elapsed    | 84       |\n",
            "|    total_timesteps | 62527    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -64.2    |\n",
            "|    critic_loss     | 0.158    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 62426    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 85.9     |\n",
            "|    ep_rew_mean     | 93.9     |\n",
            "| time/              |          |\n",
            "|    episodes        | 496      |\n",
            "|    fps             | 29       |\n",
            "|    time_elapsed    | 94       |\n",
            "|    total_timesteps | 62802    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -65.5    |\n",
            "|    critic_loss     | 0.145    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 62701    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 85.4     |\n",
            "|    ep_rew_mean     | 93.9     |\n",
            "| time/              |          |\n",
            "|    episodes        | 500      |\n",
            "|    fps             | 29       |\n",
            "|    time_elapsed    | 105      |\n",
            "|    total_timesteps | 63101    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -62.7    |\n",
            "|    critic_loss     | 0.138    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 63000    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 85.4     |\n",
            "|    ep_rew_mean     | 93.9     |\n",
            "| time/              |          |\n",
            "|    episodes        | 504      |\n",
            "|    fps             | 29       |\n",
            "|    time_elapsed    | 113      |\n",
            "|    total_timesteps | 63376    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -65.4    |\n",
            "|    critic_loss     | 0.178    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 63275    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 83.2     |\n",
            "|    ep_rew_mean     | 94       |\n",
            "| time/              |          |\n",
            "|    episodes        | 508      |\n",
            "|    fps             | 29       |\n",
            "|    time_elapsed    | 126      |\n",
            "|    total_timesteps | 63750    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -65.5    |\n",
            "|    critic_loss     | 0.187    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 63649    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 83       |\n",
            "|    ep_rew_mean     | 94       |\n",
            "| time/              |          |\n",
            "|    episodes        | 512      |\n",
            "|    fps             | 29       |\n",
            "|    time_elapsed    | 136      |\n",
            "|    total_timesteps | 64029    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -64.5    |\n",
            "|    critic_loss     | 0.134    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 63928    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 82.8     |\n",
            "|    ep_rew_mean     | 94       |\n",
            "| time/              |          |\n",
            "|    episodes        | 516      |\n",
            "|    fps             | 29       |\n",
            "|    time_elapsed    | 146      |\n",
            "|    total_timesteps | 64301    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -66.5    |\n",
            "|    critic_loss     | 0.239    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 64200    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 82.1     |\n",
            "|    ep_rew_mean     | 94       |\n",
            "| time/              |          |\n",
            "|    episodes        | 520      |\n",
            "|    fps             | 29       |\n",
            "|    time_elapsed    | 156      |\n",
            "|    total_timesteps | 64595    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -66      |\n",
            "|    critic_loss     | 0.15     |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 64494    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 82.8     |\n",
            "|    ep_rew_mean     | 94       |\n",
            "| time/              |          |\n",
            "|    episodes        | 524      |\n",
            "|    fps             | 29       |\n",
            "|    time_elapsed    | 168      |\n",
            "|    total_timesteps | 64950    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -64.9    |\n",
            "|    critic_loss     | 0.118    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 64849    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 80.8     |\n",
            "|    ep_rew_mean     | 94       |\n",
            "| time/              |          |\n",
            "|    episodes        | 528      |\n",
            "|    fps             | 29       |\n",
            "|    time_elapsed    | 178      |\n",
            "|    total_timesteps | 65218    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -65.5    |\n",
            "|    critic_loss     | 0.203    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 65117    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 80.8     |\n",
            "|    ep_rew_mean     | 93.9     |\n",
            "| time/              |          |\n",
            "|    episodes        | 532      |\n",
            "|    fps             | 29       |\n",
            "|    time_elapsed    | 187      |\n",
            "|    total_timesteps | 65500    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -65.4    |\n",
            "|    critic_loss     | 0.194    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 65399    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 85.4     |\n",
            "|    ep_rew_mean     | 93.8     |\n",
            "| time/              |          |\n",
            "|    episodes        | 536      |\n",
            "|    fps             | 29       |\n",
            "|    time_elapsed    | 217      |\n",
            "|    total_timesteps | 66340    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -66.9    |\n",
            "|    critic_loss     | 0.109    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 66239    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 85.7     |\n",
            "|    ep_rew_mean     | 93.7     |\n",
            "| time/              |          |\n",
            "|    episodes        | 540      |\n",
            "|    fps             | 29       |\n",
            "|    time_elapsed    | 228      |\n",
            "|    total_timesteps | 66664    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -66.1    |\n",
            "|    critic_loss     | 0.128    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 66563    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 85.8     |\n",
            "|    ep_rew_mean     | 93.7     |\n",
            "| time/              |          |\n",
            "|    episodes        | 544      |\n",
            "|    fps             | 29       |\n",
            "|    time_elapsed    | 238      |\n",
            "|    total_timesteps | 66947    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -66.3    |\n",
            "|    critic_loss     | 0.423    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 66846    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 87.2     |\n",
            "|    ep_rew_mean     | 93.7     |\n",
            "| time/              |          |\n",
            "|    episodes        | 548      |\n",
            "|    fps             | 29       |\n",
            "|    time_elapsed    | 259      |\n",
            "|    total_timesteps | 67536    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -64.1    |\n",
            "|    critic_loss     | 0.0984   |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 67435    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 87.2     |\n",
            "|    ep_rew_mean     | 93.7     |\n",
            "| time/              |          |\n",
            "|    episodes        | 552      |\n",
            "|    fps             | 29       |\n",
            "|    time_elapsed    | 269      |\n",
            "|    total_timesteps | 67818    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -65.5    |\n",
            "|    critic_loss     | 0.0729   |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 67717    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 86.8     |\n",
            "|    ep_rew_mean     | 93.7     |\n",
            "| time/              |          |\n",
            "|    episodes        | 556      |\n",
            "|    fps             | 28       |\n",
            "|    time_elapsed    | 279      |\n",
            "|    total_timesteps | 68088    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -65.6    |\n",
            "|    critic_loss     | 0.108    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 67987    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 87       |\n",
            "|    ep_rew_mean     | 93.7     |\n",
            "| time/              |          |\n",
            "|    episodes        | 560      |\n",
            "|    fps             | 28       |\n",
            "|    time_elapsed    | 290      |\n",
            "|    total_timesteps | 68390    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -65.2    |\n",
            "|    critic_loss     | 0.108    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 68289    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 87       |\n",
            "|    ep_rew_mean     | 93.7     |\n",
            "| time/              |          |\n",
            "|    episodes        | 564      |\n",
            "|    fps             | 28       |\n",
            "|    time_elapsed    | 300      |\n",
            "|    total_timesteps | 68671    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -64      |\n",
            "|    critic_loss     | 0.106    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 68570    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 88       |\n",
            "|    ep_rew_mean     | 93.7     |\n",
            "| time/              |          |\n",
            "|    episodes        | 568      |\n",
            "|    fps             | 28       |\n",
            "|    time_elapsed    | 316      |\n",
            "|    total_timesteps | 69107    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -63.9    |\n",
            "|    critic_loss     | 0.0902   |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 69006    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 86.5     |\n",
            "|    ep_rew_mean     | 93.8     |\n",
            "| time/              |          |\n",
            "|    episodes        | 572      |\n",
            "|    fps             | 28       |\n",
            "|    time_elapsed    | 326      |\n",
            "|    total_timesteps | 69383    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -66.9    |\n",
            "|    critic_loss     | 0.114    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 69282    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 85.9     |\n",
            "|    ep_rew_mean     | 93.8     |\n",
            "| time/              |          |\n",
            "|    episodes        | 576      |\n",
            "|    fps             | 28       |\n",
            "|    time_elapsed    | 337      |\n",
            "|    total_timesteps | 69673    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -66.3    |\n",
            "|    critic_loss     | 0.0916   |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 69572    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 86.1     |\n",
            "|    ep_rew_mean     | 93.8     |\n",
            "| time/              |          |\n",
            "|    episodes        | 580      |\n",
            "|    fps             | 28       |\n",
            "|    time_elapsed    | 347      |\n",
            "|    total_timesteps | 69964    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -67.5    |\n",
            "|    critic_loss     | 0.0988   |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 69863    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 84.1     |\n",
            "|    ep_rew_mean     | 93.8     |\n",
            "| time/              |          |\n",
            "|    episodes        | 584      |\n",
            "|    fps             | 28       |\n",
            "|    time_elapsed    | 357      |\n",
            "|    total_timesteps | 70234    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -64.5    |\n",
            "|    critic_loss     | 0.0914   |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 70133    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 83.4     |\n",
            "|    ep_rew_mean     | 93.8     |\n",
            "| time/              |          |\n",
            "|    episodes        | 588      |\n",
            "|    fps             | 28       |\n",
            "|    time_elapsed    | 368      |\n",
            "|    total_timesteps | 70519    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -64.9    |\n",
            "|    critic_loss     | 0.0516   |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 70418    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 83.7     |\n",
            "|    ep_rew_mean     | 93.8     |\n",
            "| time/              |          |\n",
            "|    episodes        | 592      |\n",
            "|    fps             | 28       |\n",
            "|    time_elapsed    | 382      |\n",
            "|    total_timesteps | 70895    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -66.1    |\n",
            "|    critic_loss     | 0.0575   |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 70794    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 83.8     |\n",
            "|    ep_rew_mean     | 93.8     |\n",
            "| time/              |          |\n",
            "|    episodes        | 596      |\n",
            "|    fps             | 28       |\n",
            "|    time_elapsed    | 393      |\n",
            "|    total_timesteps | 71177    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -66.4    |\n",
            "|    critic_loss     | 0.363    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 71076    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 86.9     |\n",
            "|    ep_rew_mean     | 93.7     |\n",
            "| time/              |          |\n",
            "|    episodes        | 600      |\n",
            "|    fps             | 28       |\n",
            "|    time_elapsed    | 415      |\n",
            "|    total_timesteps | 71794    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -66.6    |\n",
            "|    critic_loss     | 0.0559   |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 71693    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 87       |\n",
            "|    ep_rew_mean     | 93.6     |\n",
            "| time/              |          |\n",
            "|    episodes        | 604      |\n",
            "|    fps             | 28       |\n",
            "|    time_elapsed    | 426      |\n",
            "|    total_timesteps | 72077    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -65.2    |\n",
            "|    critic_loss     | 0.0809   |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 71976    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 86.1     |\n",
            "|    ep_rew_mean     | 93.7     |\n",
            "| time/              |          |\n",
            "|    episodes        | 608      |\n",
            "|    fps             | 28       |\n",
            "|    time_elapsed    | 437      |\n",
            "|    total_timesteps | 72364    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -66      |\n",
            "|    critic_loss     | 0.0778   |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 72263    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 86.5     |\n",
            "|    ep_rew_mean     | 93.7     |\n",
            "| time/              |          |\n",
            "|    episodes        | 612      |\n",
            "|    fps             | 28       |\n",
            "|    time_elapsed    | 448      |\n",
            "|    total_timesteps | 72675    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -66.3    |\n",
            "|    critic_loss     | 0.0632   |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 72574    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 86.5     |\n",
            "|    ep_rew_mean     | 93.7     |\n",
            "| time/              |          |\n",
            "|    episodes        | 616      |\n",
            "|    fps             | 28       |\n",
            "|    time_elapsed    | 459      |\n",
            "|    total_timesteps | 72951    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -64.3    |\n",
            "|    critic_loss     | 0.132    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 72850    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 87       |\n",
            "|    ep_rew_mean     | 93.7     |\n",
            "| time/              |          |\n",
            "|    episodes        | 620      |\n",
            "|    fps             | 28       |\n",
            "|    time_elapsed    | 472      |\n",
            "|    total_timesteps | 73298    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -65.7    |\n",
            "|    critic_loss     | 0.0919   |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 73197    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 87       |\n",
            "|    ep_rew_mean     | 93.7     |\n",
            "| time/              |          |\n",
            "|    episodes        | 624      |\n",
            "|    fps             | 28       |\n",
            "|    time_elapsed    | 485      |\n",
            "|    total_timesteps | 73653    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -65.4    |\n",
            "|    critic_loss     | 0.0775   |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 73552    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 87.9     |\n",
            "|    ep_rew_mean     | 93.7     |\n",
            "| time/              |          |\n",
            "|    episodes        | 628      |\n",
            "|    fps             | 28       |\n",
            "|    time_elapsed    | 499      |\n",
            "|    total_timesteps | 74011    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -66.9    |\n",
            "|    critic_loss     | 0.084    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 73910    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 89.6     |\n",
            "|    ep_rew_mean     | 93.7     |\n",
            "| time/              |          |\n",
            "|    episodes        | 632      |\n",
            "|    fps             | 28       |\n",
            "|    time_elapsed    | 516      |\n",
            "|    total_timesteps | 74459    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -65.8    |\n",
            "|    critic_loss     | 0.131    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 74358    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 84.5     |\n",
            "|    ep_rew_mean     | 93.8     |\n",
            "| time/              |          |\n",
            "|    episodes        | 636      |\n",
            "|    fps             | 27       |\n",
            "|    time_elapsed    | 528      |\n",
            "|    total_timesteps | 74788    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -63.6    |\n",
            "|    critic_loss     | 0.0801   |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 74687    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 84       |\n",
            "|    ep_rew_mean     | 93.8     |\n",
            "| time/              |          |\n",
            "|    episodes        | 640      |\n",
            "|    fps             | 27       |\n",
            "|    time_elapsed    | 538      |\n",
            "|    total_timesteps | 75063    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -65.1    |\n",
            "|    critic_loss     | 0.125    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 74962    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 84.2     |\n",
            "|    ep_rew_mean     | 93.8     |\n",
            "| time/              |          |\n",
            "|    episodes        | 644      |\n",
            "|    fps             | 27       |\n",
            "|    time_elapsed    | 553      |\n",
            "|    total_timesteps | 75366    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -66.1    |\n",
            "|    critic_loss     | 0.0515   |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 75265    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 81.5     |\n",
            "|    ep_rew_mean     | 93.9     |\n",
            "| time/              |          |\n",
            "|    episodes        | 648      |\n",
            "|    fps             | 27       |\n",
            "|    time_elapsed    | 565      |\n",
            "|    total_timesteps | 75689    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -65.8    |\n",
            "|    critic_loss     | 0.0457   |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 75588    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 82.1     |\n",
            "|    ep_rew_mean     | 93.9     |\n",
            "| time/              |          |\n",
            "|    episodes        | 652      |\n",
            "|    fps             | 27       |\n",
            "|    time_elapsed    | 578      |\n",
            "|    total_timesteps | 76032    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -65.6    |\n",
            "|    critic_loss     | 0.074    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 75931    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 82.2     |\n",
            "|    ep_rew_mean     | 93.9     |\n",
            "| time/              |          |\n",
            "|    episodes        | 656      |\n",
            "|    fps             | 27       |\n",
            "|    time_elapsed    | 589      |\n",
            "|    total_timesteps | 76312    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -65.9    |\n",
            "|    critic_loss     | 0.0609   |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 76211    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 83.8     |\n",
            "|    ep_rew_mean     | 93.8     |\n",
            "| time/              |          |\n",
            "|    episodes        | 660      |\n",
            "|    fps             | 27       |\n",
            "|    time_elapsed    | 606      |\n",
            "|    total_timesteps | 76768    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -65      |\n",
            "|    critic_loss     | 0.0703   |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 76667    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 83.8     |\n",
            "|    ep_rew_mean     | 93.8     |\n",
            "| time/              |          |\n",
            "|    episodes        | 664      |\n",
            "|    fps             | 27       |\n",
            "|    time_elapsed    | 617      |\n",
            "|    total_timesteps | 77055    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -65.7    |\n",
            "|    critic_loss     | 0.0634   |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 76954    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 82.2     |\n",
            "|    ep_rew_mean     | 93.9     |\n",
            "| time/              |          |\n",
            "|    episodes        | 668      |\n",
            "|    fps             | 27       |\n",
            "|    time_elapsed    | 627      |\n",
            "|    total_timesteps | 77328    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -66.1    |\n",
            "|    critic_loss     | 0.0739   |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 77227    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 83       |\n",
            "|    ep_rew_mean     | 93.9     |\n",
            "| time/              |          |\n",
            "|    episodes        | 672      |\n",
            "|    fps             | 27       |\n",
            "|    time_elapsed    | 641      |\n",
            "|    total_timesteps | 77685    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -65.2    |\n",
            "|    critic_loss     | 0.0947   |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 77584    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 85.5     |\n",
            "|    ep_rew_mean     | 93.8     |\n",
            "| time/              |          |\n",
            "|    episodes        | 676      |\n",
            "|    fps             | 27       |\n",
            "|    time_elapsed    | 660      |\n",
            "|    total_timesteps | 78226    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -66      |\n",
            "|    critic_loss     | 0.082    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 78125    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 85.3     |\n",
            "|    ep_rew_mean     | 93.8     |\n",
            "| time/              |          |\n",
            "|    episodes        | 680      |\n",
            "|    fps             | 27       |\n",
            "|    time_elapsed    | 671      |\n",
            "|    total_timesteps | 78498    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -65.8    |\n",
            "|    critic_loss     | 0.0849   |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 78397    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 86.6     |\n",
            "|    ep_rew_mean     | 93.8     |\n",
            "| time/              |          |\n",
            "|    episodes        | 684      |\n",
            "|    fps             | 27       |\n",
            "|    time_elapsed    | 686      |\n",
            "|    total_timesteps | 78896    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -65.3    |\n",
            "|    critic_loss     | 0.056    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 78795    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 90.1     |\n",
            "|    ep_rew_mean     | 93.7     |\n",
            "| time/              |          |\n",
            "|    episodes        | 688      |\n",
            "|    fps             | 27       |\n",
            "|    time_elapsed    | 710      |\n",
            "|    total_timesteps | 79533    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -67.4    |\n",
            "|    critic_loss     | 0.0515   |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 79432    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 89.1     |\n",
            "|    ep_rew_mean     | 93.7     |\n",
            "| time/              |          |\n",
            "|    episodes        | 692      |\n",
            "|    fps             | 27       |\n",
            "|    time_elapsed    | 720      |\n",
            "|    total_timesteps | 79801    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -67.6    |\n",
            "|    critic_loss     | 0.0867   |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 79700    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 88.9     |\n",
            "|    ep_rew_mean     | 93.7     |\n",
            "| time/              |          |\n",
            "|    episodes        | 696      |\n",
            "|    fps             | 22       |\n",
            "|    time_elapsed    | 3        |\n",
            "|    total_timesteps | 80070    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -66.4    |\n",
            "|    critic_loss     | 0.0857   |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 79969    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 86.9     |\n",
            "|    ep_rew_mean     | 93.8     |\n",
            "| time/              |          |\n",
            "|    episodes        | 700      |\n",
            "|    fps             | 25       |\n",
            "|    time_elapsed    | 19       |\n",
            "|    total_timesteps | 80485    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -64      |\n",
            "|    critic_loss     | 0.0644   |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 80384    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 87       |\n",
            "|    ep_rew_mean     | 93.8     |\n",
            "| time/              |          |\n",
            "|    episodes        | 704      |\n",
            "|    fps             | 25       |\n",
            "|    time_elapsed    | 30       |\n",
            "|    total_timesteps | 80780    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -66.3    |\n",
            "|    critic_loss     | 0.063    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 80679    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 86.9     |\n",
            "|    ep_rew_mean     | 93.8     |\n",
            "| time/              |          |\n",
            "|    episodes        | 708      |\n",
            "|    fps             | 26       |\n",
            "|    time_elapsed    | 39       |\n",
            "|    total_timesteps | 81051    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -65.6    |\n",
            "|    critic_loss     | 0.082    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 80950    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 87.2     |\n",
            "|    ep_rew_mean     | 93.7     |\n",
            "| time/              |          |\n",
            "|    episodes        | 712      |\n",
            "|    fps             | 26       |\n",
            "|    time_elapsed    | 52       |\n",
            "|    total_timesteps | 81393    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -64.8    |\n",
            "|    critic_loss     | 0.0518   |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 81292    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 87.9     |\n",
            "|    ep_rew_mean     | 93.7     |\n",
            "| time/              |          |\n",
            "|    episodes        | 716      |\n",
            "|    fps             | 26       |\n",
            "|    time_elapsed    | 66       |\n",
            "|    total_timesteps | 81743    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -66.1    |\n",
            "|    critic_loss     | 0.0774   |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 81642    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 88.9     |\n",
            "|    ep_rew_mean     | 93.7     |\n",
            "| time/              |          |\n",
            "|    episodes        | 720      |\n",
            "|    fps             | 26       |\n",
            "|    time_elapsed    | 84       |\n",
            "|    total_timesteps | 82191    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -67      |\n",
            "|    critic_loss     | 0.0559   |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 82090    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 88.4     |\n",
            "|    ep_rew_mean     | 93.8     |\n",
            "| time/              |          |\n",
            "|    episodes        | 724      |\n",
            "|    fps             | 26       |\n",
            "|    time_elapsed    | 95       |\n",
            "|    total_timesteps | 82493    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -64.9    |\n",
            "|    critic_loss     | 0.0592   |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 82392    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 87.6     |\n",
            "|    ep_rew_mean     | 93.8     |\n",
            "| time/              |          |\n",
            "|    episodes        | 728      |\n",
            "|    fps             | 26       |\n",
            "|    time_elapsed    | 106      |\n",
            "|    total_timesteps | 82773    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -65.7    |\n",
            "|    critic_loss     | 0.069    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 82672    |\n",
            "---------------------------------\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-425c07c48d5a>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mTIMESTEPS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m20000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTIMESTEPS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset_num_timesteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_log_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"DDPG\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{models_dir}/{TIMESTEPS*i}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/stable_baselines3/ddpg/ddpg.py\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0mprogress_bar\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     ) -> SelfDDPG:\n\u001b[0;32m--> 123\u001b[0;31m         return super().learn(\n\u001b[0m\u001b[1;32m    124\u001b[0m             \u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/stable_baselines3/td3/td3.py\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0mprogress_bar\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m     ) -> SelfTD3:\n\u001b[0;32m--> 222\u001b[0;31m         return super().learn(\n\u001b[0m\u001b[1;32m    223\u001b[0m             \u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/stable_baselines3/common/off_policy_algorithm.py\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    345\u001b[0m                 \u001b[0;31m# Special case when the user passes `gradient_steps=0`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgradient_steps\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgradient_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    348\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_training_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/stable_baselines3/td3/td3.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, gradient_steps, batch_size)\u001b[0m\n\u001b[1;32m    197\u001b[0m                 \u001b[0;31m# Optimize the actor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mactor_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    519\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m             )\n\u001b[0;32m--> 521\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    287\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 289\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    290\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    766\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 768\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    769\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "models_dir = \"models/Mountain-1726248189.0127406\"\n",
        "model_path = f\"{models_dir}/40000\"\n",
        "best_model = DDPG.load(model_path, env=env)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OETVhKGQ_KZ7",
        "outputId": "8caf054a-8694-48dc-a489-d11d4d17eaf1"
      },
      "id": "OETVhKGQ_KZ7",
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_model."
      ],
      "metadata": {
        "id": "DQYXYAaw_UeQ"
      },
      "id": "DQYXYAaw_UeQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GBOzDUs0q-jM",
        "outputId": "d0437967-e109-41bb-b3c3-9672c409371d"
      },
      "id": "GBOzDUs0q-jM",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check model performance\n",
        "# load the best model you observed from tensorboard - the one reach the goal/ obtaining highest return\n",
        "models_dir = \"models/Mountain-1726248189.0127406\"\n",
        "model_path = f\"{models_dir}/40000\"\n",
        "best_model = DDPG.load(model_path, env=env)\n",
        "\n",
        "\n",
        "obs = env.reset()\n",
        "\n",
        "reward_records = []\n",
        "\n",
        "for i in tqdm(range(5)):\n",
        "  cum_reward = 0\n",
        "  while True:\n",
        "          action, _states = best_model.predict(obs)\n",
        "          obs, rewards, dones, info = env.step(action)\n",
        "          cum_reward += rewards\n",
        "          env.render()\n",
        "  reward_records.append(cum_reward)\n",
        "  if np.average(reward_records[-2]) > 90:\n",
        "        break\n",
        "\n",
        "obs = env.reset()\n",
        "while True:\n",
        "    action, _states = best_model.predict(obs)\n",
        "    obs, rewards, dones, info = env.step(action)\n",
        "    env.render()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        },
        "id": "A-1qk0T7_Yu7",
        "outputId": "cb78f1a9-c8c9-4535-8321-9fc7206366d9"
      },
      "id": "A-1qk0T7_Yu7",
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/5 [07:10<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-8ae3f34a4b85>\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m           \u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrewards\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdones\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m           \u001b[0mcum_reward\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mrewards\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m           \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m   \u001b[0mreward_records\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcum_reward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreward_records\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m90\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/stable_baselines3/common/vec_env/dummy_vec_env.py\u001b[0m in \u001b[0;36mrender\u001b[0;34m(self, mode)\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0;34m:\u001b[0m\u001b[0mparam\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mThe\u001b[0m \u001b[0mrendering\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m         \"\"\"\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_save_obs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv_idx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mVecEnvObs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/stable_baselines3/common/vec_env/base_vec_env.py\u001b[0m in \u001b[0;36mrender\u001b[0;34m(self, mode)\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"rgb_array\"\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"human\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m             \u001b[0;31m# call the render method of the environments\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 255\u001b[0;31m             \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m             \u001b[0;31m# Create a big image by tiling images from subprocesses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m             \u001b[0mbigimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtile_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/stable_baselines3/common/vec_env/dummy_vec_env.py\u001b[0m in \u001b[0;36mget_images\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     92\u001b[0m             )\n\u001b[1;32m     93\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menvs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0menv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menvs\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/stable_baselines3/common/vec_env/dummy_vec_env.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     92\u001b[0m             )\n\u001b[1;32m     93\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menvs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0menv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menvs\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gymnasium/core.py\u001b[0m in \u001b[0;36mrender\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    469\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mRenderFrame\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mRenderFrame\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m         \u001b[0;34m\"\"\"Uses the :meth:`render` of the :attr:`env` that can be overwritten to change the returned data.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 471\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    472\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    473\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gymnasium/core.py\u001b[0m in \u001b[0;36mrender\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    469\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mRenderFrame\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mRenderFrame\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m         \u001b[0;34m\"\"\"Uses the :meth:`render` of the :attr:`env` that can be overwritten to change the returned data.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 471\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    472\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    473\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gymnasium/wrappers/order_enforcing.py\u001b[0m in \u001b[0;36mrender\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m                 \u001b[0;34m\"set `disable_render_order_enforcing=True` on the OrderEnforcer wrapper.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             )\n\u001b[0;32m---> 70\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gymnasium/wrappers/env_checker.py\u001b[0m in \u001b[0;36mrender\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0menv_render_passive_checker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gymnasium/envs/classic_control/continuous_mountain_car.py\u001b[0m in \u001b[0;36mrender\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"rgb_array\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             return np.transpose(\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpygame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msurfarray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpixels3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscreen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m             )\n\u001b[1;32m    297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 250\n",
        "\n",
        "reward_records = []\n",
        "for i in tqdm(range(20)):\n",
        "    # Run episode till done\n",
        "    s = env.reset()\n",
        "    done = False\n",
        "    cum_reward = 0\n",
        "    while not done:\n",
        "      #  a = pick_sample(s)\n",
        "\n",
        "        # a = pick_sample(s,0,)\n",
        "        # s_next, r, done, _ = env.step(a)\n",
        "        # buffer.add([s, a, r, s_next, float(done)])\n",
        "        # cum_reward += r\n",
        "\n",
        "\n",
        "        action, _states = best_model.predict(obs)\n",
        "        obs, rewards, dones, info = env.step(action)\n",
        "        cum_reward += rewards\n",
        "\n",
        "\n",
        "    # Output total rewards in episode (max 500)\n",
        "    # print(\"Run episode{} with rewards {}\".format(i, cum_reward), end=\"\\r\")\n",
        "    reward_records.append(cum_reward)\n",
        "\n",
        "    # stop if reward mean > 475.0\n",
        "    if np.average(reward_records[-20:]) > 90:\n",
        "        break\n",
        "\n",
        "print(\"\\nDone\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        },
        "id": "-ol-GHQh3Tnj",
        "outputId": "1c2a23b0-65dc-49d0-baee-99b5e34e4ca2"
      },
      "id": "-ol-GHQh3Tnj",
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/20 [01:43<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-9c6c117e2ae6>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbest_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrewards\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdones\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mcum_reward\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mrewards\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/stable_baselines3/common/base_class.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, observation, state, episode_start, deterministic)\u001b[0m\n\u001b[1;32m    554\u001b[0m             \u001b[0;34m(\u001b[0m\u001b[0mused\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrecurrent\u001b[0m \u001b[0mpolicies\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m         \"\"\"\n\u001b[0;32m--> 556\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolicy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepisode_start\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeterministic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    557\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mset_random_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/stable_baselines3/common/policies.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, observation, state, episode_start, deterministic)\u001b[0m\n\u001b[1;32m    366\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 368\u001b[0;31m             \u001b[0mactions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeterministic\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdeterministic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    369\u001b[0m         \u001b[0;31m# Convert to numpy, and reshape to the original action shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m         \u001b[0mactions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mactions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/stable_baselines3/td3/policies.py\u001b[0m in \u001b[0;36m_predict\u001b[0;34m(self, observation, deterministic)\u001b[0m\n\u001b[1;32m    240\u001b[0m         \u001b[0;31m# Note: the deterministic deterministic parameter is ignored in the case of TD3.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m         \u001b[0;31m#   Predictions are always deterministic.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 242\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mset_training_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/stable_baselines3/td3/policies.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, obs)\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0;31m# assert deterministic, 'The TD3 actor only outputs deterministic actions'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m         \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures_extractor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/stable_baselines3/common/policies.py\u001b[0m in \u001b[0;36mextract_features\u001b[0;34m(self, obs, features_extractor)\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0;34m:\u001b[0m\u001b[0;32mreturn\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mThe\u001b[0m \u001b[0mextracted\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m         \"\"\"\n\u001b[0;32m--> 130\u001b[0;31m         \u001b[0mpreprocessed_obs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess_obs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobservation_space\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalize_images\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfeatures_extractor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreprocessed_obs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/stable_baselines3/common/preprocessing.py\u001b[0m in \u001b[0;36mpreprocess_obs\u001b[0;34m(obs, observation_space, normalize_images)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservation_space\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBox\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mnormalize_images\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_image_space\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservation_space\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m255.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/stable_baselines3/common/preprocessing.py\u001b[0m in \u001b[0;36mis_image_space\u001b[0;34m(observation_space, check_channels, normalized_image)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \"\"\"\n\u001b[1;32m     48\u001b[0m     \u001b[0mcheck_dtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_bounds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnormalized_image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservation_space\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBox\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservation_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;31m# Check the type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcheck_dtype\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mobservation_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "# Generate recent 50 interval average\n",
        "average_reward = []\n",
        "for idx in range(len(reward_records)):\n",
        "    avg_list = np.empty(shape=(1,), dtype=int)\n",
        "    if idx < 50:\n",
        "        avg_list = reward_records[:idx+1]\n",
        "    else:\n",
        "        avg_list = reward_records[idx-49:idx+1]\n",
        "    average_reward.append(np.average(avg_list))\n",
        "plt.plot(reward_records, label='reward')\n",
        "plt.plot(average_reward, label='average reward')\n",
        "plt.xlabel('N steps')\n",
        "plt.ylabel('Reward')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "oZv_DyOHt1Gp"
      },
      "id": "oZv_DyOHt1Gp",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 250\n",
        "\n",
        "reward_records = []\n",
        "for i in tqdm(range(2000)):\n",
        "    # Run episode till done\n",
        "    s = env.reset()\n",
        "    done = False\n",
        "    cum_reward = 0\n",
        "    while not done:\n",
        "      #  a = pick_sample(s)\n",
        "\n",
        "        a = pick_sample(s,0,)\n",
        "        s_next, r, done, _ = env.step(a)\n",
        "        buffer.add([s, a, r, s_next, float(done)])\n",
        "        cum_reward += r\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        # Train (optimize parameters)\n",
        "        if buffer.length() >= batch_size:\n",
        "            states, actions, rewards, n_states, dones = buffer.sample(batch_size)\n",
        "            optimize(states, actions, rewards, n_states, dones)\n",
        "            update_target()\n",
        "        s = s_next\n",
        "\n",
        "    # Output total rewards in episode (max 500)\n",
        "    # print(\"Run episode{} with rewards {}\".format(i, cum_reward), end=\"\\r\")\n",
        "    reward_records.append(cum_reward)\n",
        "\n",
        "    # stop if reward mean > 475.0\n",
        "    if np.average(reward_records[-50:]) > 475.0:\n",
        "        break\n",
        "\n",
        "print(\"\\nDone\")\n"
      ],
      "metadata": {
        "id": "T4yLxbjeEcTA"
      },
      "id": "T4yLxbjeEcTA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " for e in range(max_episodes):\n",
        "            state = self.env.reset()\n",
        "            state = torch.tensor(state, device=device, dtype=dtype).unsqueeze(0)\n",
        "            episode_reward = 0\n",
        "            for t in range(max_time_steps):\n",
        "                #self.env.render()\n",
        "                action = self.select_action(state, noise_factor)\n",
        "                next_state, reward, done, _ = self.env.step(action[0])         # Sample a transition\n",
        "                episode_reward += reward\n",
        "\n",
        "                next_state = torch.tensor(next_state, device=device, dtype=dtype).unsqueeze(0)\n",
        "                reward = torch.tensor(\n",
        "                    [reward], device=device, dtype=dtype\n",
        "                ).unsqueeze(0)\n",
        "                done = torch.tensor(\n",
        "                    [done], device=device, dtype=dtype\n",
        "                ).unsqueeze(0)\n",
        "\n",
        "                self.store_transition(\n",
        "                    state, action, reward, next_state, done\n",
        "                )                # Store the transition in the replay buffer\n",
        "\n",
        "                state = next_state\n",
        "\n",
        "                sample_batch = self.sample_batch(64)\n"
      ],
      "metadata": {
        "id": "H1JlF9qvmFxu"
      },
      "id": "H1JlF9qvmFxu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zwmlCp4R9AvV"
      },
      "id": "zwmlCp4R9AvV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hkDLEA9N9A1C"
      },
      "id": "hkDLEA9N9A1C",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qq3cKL5_9A39"
      },
      "id": "qq3cKL5_9A39",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}